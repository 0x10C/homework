{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepInf_GCN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "class InfluenceDataSet(Dataset):\n",
    "    def __init__(self, file_dir, embedding_dim, seed, shuffle, model):\n",
    "        self.graphs = np.load(os.path.join(file_dir, \"adjacency_matrix.npy\")).astype(np.float32)\n",
    "\n",
    "        # self-loop trick, the input graphs should have no self-loop\n",
    "        identity = np.identity(self.graphs.shape[1])\n",
    "        self.graphs += identity\n",
    "        self.graphs[self.graphs != 0] = 1.0\n",
    "        if model == \"gat\" or model == \"pscn\":\n",
    "            self.graphs = self.graphs.astype(np.dtype('B'))\n",
    "        elif model == \"gcn\":\n",
    "            # normalized graph laplacian for GCN: D^{-1/2}AD^{-1/2}\n",
    "            for i in range(len(self.graphs)):\n",
    "                graph = self.graphs[i]\n",
    "                d_root_inv = 1. / np.sqrt(np.sum(graph, axis=1))\n",
    "                graph = (graph.T * d_root_inv).T * d_root_inv\n",
    "                self.graphs[i] = graph\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        logger.info(\"graphs loaded!\")\n",
    "\n",
    "        # wheather a user has been influenced\n",
    "        # wheather he/she is the ego user\n",
    "        self.influence_features = np.load(\n",
    "                os.path.join(file_dir, \"influence_feature.npy\")).astype(np.float32)\n",
    "        logger.info(\"influence features loaded!\")\n",
    "\n",
    "        self.labels = np.load(os.path.join(file_dir, \"label.npy\"))\n",
    "        logger.info(\"labels loaded!\")\n",
    "\n",
    "        self.vertices = np.load(os.path.join(file_dir, \"vertex_id.npy\"))\n",
    "        logger.info(\"vertex ids loaded!\")\n",
    "\n",
    "        if shuffle:\n",
    "            self.graphs, self.influence_features, self.labels, self.vertices = \\\n",
    "                    sklearn.utils.shuffle(\n",
    "                        self.graphs, self.influence_features,\n",
    "                        self.labels, self.vertices,\n",
    "                        random_state=seed\n",
    "                    )\n",
    "\n",
    "        vertex_features = np.load(os.path.join(file_dir, \"vertex_feature.npy\"))\n",
    "        vertex_features = preprocessing.scale(vertex_features)\n",
    "        self.vertex_features = torch.FloatTensor(vertex_features)\n",
    "        logger.info(\"global vertex features loaded!\")\n",
    "\n",
    "        embedding_path = os.path.join(file_dir, \"deepwalk.emb_%d\" % embedding_dim)\n",
    "        max_vertex_idx = np.max(self.vertices)\n",
    "        embedding = load_w2v_feature(embedding_path, max_vertex_idx)\n",
    "        self.embedding = torch.FloatTensor(embedding)\n",
    "        logger.info(\"%d-dim embedding loaded!\", embedding_dim)\n",
    "\n",
    "        self.N = self.graphs.shape[0]\n",
    "        logger.info(\"%d ego networks loaded, each with size %d\" % (self.N, self.graphs.shape[1]))\n",
    "\n",
    "        n_classes = self.get_num_class()\n",
    "        class_weight = self.N / (n_classes * np.bincount(self.labels))\n",
    "        self.class_weight = torch.FloatTensor(class_weight)\n",
    "\n",
    "    def get_embedding(self):\n",
    "        return self.embedding\n",
    "\n",
    "    def get_vertex_features(self):\n",
    "        return self.vertex_features\n",
    "\n",
    "    def get_feature_dimension(self):\n",
    "        return self.influence_features.shape[-1]\n",
    "\n",
    "    def get_num_class(self):\n",
    "        return np.unique(self.labels).shape[0]\n",
    "\n",
    "    def get_class_weight(self):\n",
    "        return self.class_weight\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.influence_features[idx], self.labels[idx], self.vertices[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_w2v_feature(file, max_idx=0):\n",
    "    with open(file, \"rb\") as f:\n",
    "        nu = 0\n",
    "        for line in f:\n",
    "            content = line.strip().split()\n",
    "            nu += 1\n",
    "            if nu == 1:\n",
    "                n, d = int(content[0]), int(content[1])\n",
    "                feature = [[0.] * d for i in range(max(n, max_idx + 1))]\n",
    "                continue\n",
    "            index = int(content[0])\n",
    "            while len(feature) <= index:\n",
    "                feature.append([0.] * d)\n",
    "            for i, x in enumerate(content[1:]):\n",
    "                feature[index][i] = float(x)\n",
    "    for item in feature:\n",
    "        assert len(item) == d\n",
    "    return np.array(feature, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "logger = logging.getLogger(__name__)\n",
    "influence_dataset = InfluenceDataSet(\n",
    "            \"weibo/\", 64, 42, False, \"gcn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-18 10:58:50,071 tensorboard logging to log/gcn\n"
     ]
    }
   ],
   "source": [
    "from tensorboard_logger import tensorboard_logger\n",
    "import shutil\n",
    "tensorboard_log_dir = 'log/%s' % ('gcn')\n",
    "os.makedirs(tensorboard_log_dir, exist_ok=True)\n",
    "shutil.rmtree(tensorboard_log_dir)\n",
    "tensorboard_logger.configure(tensorboard_log_dir)\n",
    "logger.info('tensorboard logging to %s', tensorboard_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import Sampler\n",
    "class ChunkSampler(Sampler):\n",
    "    \"\"\"\n",
    "    Samples elements sequentially from some offset.\n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start=0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "N = len(influence_dataset)   \n",
    "train_start,  valid_start, test_start = \\\n",
    "        0, int(N * 0.75 / 100), int(N * (0.75 + 0.125))\n",
    "    \n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(influence_dataset, batch_size=1024,\n",
    "                        sampler=ChunkSampler(valid_start - train_start, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(influence_dataset, batch_size=1024,\n",
    "                        sampler=ChunkSampler(test_start - valid_start, valid_start))\n",
    "test_loader = DataLoader(influence_dataset, batch_size=1024,\n",
    "                        sampler=ChunkSampler(N - test_start, test_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(influence_dataset)\n",
    "n_classes = 2\n",
    "hidden_units = \"128,128\"\n",
    "class_weight = influence_dataset.get_class_weight() \\\n",
    "        if False else torch.ones(n_classes)\n",
    "logger.info(\"class_weight=%.2f:%.2f\", class_weight[0], class_weight[1])\n",
    "\n",
    "feature_dim = influence_dataset.get_feature_dimension()\n",
    "n_units = [feature_dim] + [int(x) for x in hidden_units.strip().split(\",\")] + [n_classes]\n",
    "logger.info(\"feature dimension=%d\", feature_dim)\n",
    "logger.info(\"number of classes=%d\", n_classes)\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGraphConvolution(Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(BatchGraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "            init.constant_(self.bias, 0)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, x, lap):\n",
    "        expand_weight = self.weight.expand(x.shape[0], -1, -1)\n",
    "        support = torch.bmm(x, expand_weight)\n",
    "        output = torch.bmm(lap, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGCN(nn.Module):\n",
    "    def __init__(self, n_units, dropout, pretrained_emb, vertex_feature,\n",
    "            use_vertex_feature, fine_tune=False, instance_normalization=False):\n",
    "        super(BatchGCN, self).__init__()\n",
    "        self.num_layer = len(n_units) - 1\n",
    "        self.dropout = dropout\n",
    "        self.inst_norm = instance_normalization\n",
    "        if self.inst_norm:\n",
    "            self.norm = nn.InstanceNorm1d(pretrained_emb.size(1), momentum=0.0, affine=True)\n",
    "\n",
    "        # https://discuss.pytorch.org/t/can-we-use-pre-trained-word-embeddings-for-weight-initialization-in-nn-embedding/1222/2\n",
    "        self.embedding = nn.Embedding(pretrained_emb.shape[0], pretrained_emb.shape[1])\n",
    "        self.embedding.weight = nn.Parameter(pretrained_emb)\n",
    "        self.embedding.weight.requires_grad = fine_tune\n",
    "        n_units[0] += pretrained_emb.shape[1]\n",
    "\n",
    "        self.use_vertex_feature = use_vertex_feature\n",
    "        if self.use_vertex_feature:\n",
    "            self.vertex_feature = nn.Embedding(vertex_feature.shape[0], vertex_feature.shape[1])\n",
    "            self.vertex_feature.weight = nn.Parameter(vertex_feature)\n",
    "            self.vertex_feature.weight.requires_grad = False\n",
    "            n_units[0] += vertex_feature.shape[1]\n",
    "\n",
    "        self.layer_stack = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.num_layer):\n",
    "            self.layer_stack.append(\n",
    "                    BatchGraphConvolution(n_units[i], n_units[i + 1])\n",
    "                    )\n",
    "\n",
    "    def forward(self, x, vertices, lap):\n",
    "        emb = self.embedding(vertices)\n",
    "        if self.inst_norm:\n",
    "            emb = self.norm(emb.transpose(1, 2)).transpose(1, 2)\n",
    "        x = torch.cat((x, emb), dim=2)\n",
    "        if self.use_vertex_feature:\n",
    "            vfeature = self.vertex_feature(vertices)\n",
    "            x = torch.cat((x, vfeature), dim=2)\n",
    "        for i, gcn_layer in enumerate(self.layer_stack):\n",
    "            x = gcn_layer(x, lap)\n",
    "            if i + 1 < self.num_layer:\n",
    "                x = F.elu(x)\n",
    "                x = F.dropout(x, self.dropout, training=self.training)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BatchGCN(pretrained_emb=influence_dataset.get_embedding(),\n",
    "                vertex_feature=influence_dataset.get_vertex_features(),\n",
    "                use_vertex_feature=False,\n",
    "                n_units=n_units,\n",
    "                dropout=dropout,\n",
    "                instance_normalization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "params = [{'params': filter(lambda p: p.requires_grad, model.parameters())\n",
    "   }]\n",
    "optimizer = optim.Adagrad(params, lr=0.1, weight_decay=5e-4)\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader, valid_loader, test_loader, log_desc='train_'):\n",
    "    model.train()\n",
    "    loss = 0.\n",
    "    total = 0.\n",
    "    for i_batch, batch in enumerate(train_loader):\n",
    "        graph, features, labels, vertices = batch\n",
    "        bs = graph.shape[0]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(features, vertices, graph)\n",
    "        if True:\n",
    "            output = output[:, -1, :]\n",
    "        loss_train = F.nll_loss(output, labels, class_weight)\n",
    "        loss += bs * loss_train.item()\n",
    "        total += bs\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "    logger.info(\"train loss in this epoch %f\", loss / total)\n",
    "    tensorboard_logger.log_value('train_loss', loss / total, epoch + 1)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        logger.info(\"epoch %d, checkpoint!\", epoch)\n",
    "        best_thr = evaluate(epoch, valid_loader, return_best_thr=True, log_desc='valid_')\n",
    "        evaluate(epoch, test_loader, thr=best_thr, log_desc='test_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-18 11:02:25,877 training...\n",
      "2020-07-18 11:02:26,755 train loss in this epoch 0.537798\n",
      "2020-07-18 11:02:27,635 train loss in this epoch 0.536948\n",
      "2020-07-18 11:02:28,501 train loss in this epoch 0.536713\n",
      "2020-07-18 11:02:29,385 train loss in this epoch 0.533474\n",
      "2020-07-18 11:02:30,263 train loss in this epoch 0.528936\n",
      "2020-07-18 11:02:31,154 train loss in this epoch 0.528339\n",
      "2020-07-18 11:02:32,044 train loss in this epoch 0.528182\n",
      "2020-07-18 11:02:32,920 train loss in this epoch 0.526966\n",
      "2020-07-18 11:02:33,808 train loss in this epoch 0.528220\n",
      "2020-07-18 11:02:34,670 train loss in this epoch 0.527923\n",
      "2020-07-18 11:02:34,672 epoch 9, checkpoint!\n",
      "2020-07-18 11:03:41,257 valid_loss: 0.5310 AUC: 0.6747 Prec: 0.4142 Rec: 0.0087 F1: 0.0170\n",
      "2020-07-18 11:03:41,824 best threshold=-1.671974, f1=0.4654\n",
      "2020-07-18 11:03:50,752 using threshold -1.6720\n",
      "2020-07-18 11:03:51,033 test_loss: 0.5321 AUC: 0.6733 Prec: 0.3336 Rec: 0.7600 F1: 0.4637\n",
      "2020-07-18 11:03:51,879 train loss in this epoch 0.528446\n",
      "2020-07-18 11:03:52,748 train loss in this epoch 0.525743\n",
      "2020-07-18 11:03:53,622 train loss in this epoch 0.524624\n",
      "2020-07-18 11:03:54,498 train loss in this epoch 0.522211\n",
      "2020-07-18 11:03:55,346 train loss in this epoch 0.522528\n",
      "2020-07-18 11:03:56,198 train loss in this epoch 0.522408\n",
      "2020-07-18 11:03:57,057 train loss in this epoch 0.523533\n",
      "2020-07-18 11:03:57,945 train loss in this epoch 0.521400\n",
      "2020-07-18 11:03:58,796 train loss in this epoch 0.521724\n",
      "2020-07-18 11:03:59,643 train loss in this epoch 0.521711\n",
      "2020-07-18 11:03:59,645 epoch 19, checkpoint!\n",
      "2020-07-18 11:05:05,730 valid_loss: 0.5264 AUC: 0.6790 Prec: 0.4977 Rec: 0.0264 F1: 0.0502\n",
      "2020-07-18 11:05:06,298 best threshold=-1.634526, f1=0.4670\n",
      "2020-07-18 11:05:14,847 using threshold -1.6345\n",
      "2020-07-18 11:05:15,227 test_loss: 0.5272 AUC: 0.6779 Prec: 0.3340 Rec: 0.7727 F1: 0.4664\n",
      "2020-07-18 11:05:16,091 train loss in this epoch 0.520387\n",
      "2020-07-18 11:05:16,953 train loss in this epoch 0.521113\n",
      "2020-07-18 11:05:17,835 train loss in this epoch 0.520388\n",
      "2020-07-18 11:05:18,760 train loss in this epoch 0.518336\n",
      "2020-07-18 11:05:19,995 train loss in this epoch 0.518118\n",
      "2020-07-18 11:05:21,021 train loss in this epoch 0.519218\n",
      "2020-07-18 11:05:21,990 train loss in this epoch 0.517812\n",
      "2020-07-18 11:05:22,869 train loss in this epoch 0.518382\n",
      "2020-07-18 11:05:23,749 train loss in this epoch 0.519328\n",
      "2020-07-18 11:05:24,616 train loss in this epoch 0.517912\n",
      "2020-07-18 11:05:24,618 epoch 29, checkpoint!\n",
      "2020-07-18 11:06:31,163 valid_loss: 0.5255 AUC: 0.6823 Prec: 0.5136 Rec: 0.0319 F1: 0.0600\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in true_divide\n",
      "2020-07-18 11:06:31,731 best threshold=-1.648953, f1=0.4684\n",
      "2020-07-18 11:06:41,070 using threshold -1.6490\n",
      "2020-07-18 11:06:41,508 test_loss: 0.5261 AUC: 0.6815 Prec: 0.3352 Rec: 0.7692 F1: 0.4669\n",
      "2020-07-18 11:06:42,405 train loss in this epoch 0.519337\n",
      "2020-07-18 11:06:43,256 train loss in this epoch 0.515091\n",
      "2020-07-18 11:06:44,137 train loss in this epoch 0.516936\n",
      "2020-07-18 11:06:45,032 train loss in this epoch 0.514123\n",
      "2020-07-18 11:06:45,960 train loss in this epoch 0.514887\n",
      "2020-07-18 11:06:46,976 train loss in this epoch 0.513810\n",
      "2020-07-18 11:06:47,932 train loss in this epoch 0.516074\n",
      "2020-07-18 11:06:48,813 train loss in this epoch 0.514883\n",
      "2020-07-18 11:06:49,691 train loss in this epoch 0.514217\n",
      "2020-07-18 11:06:50,579 train loss in this epoch 0.513042\n",
      "2020-07-18 11:06:50,580 epoch 39, checkpoint!\n",
      "2020-07-18 11:07:55,266 valid_loss: 0.5240 AUC: 0.6848 Prec: 0.5217 Rec: 0.0407 F1: 0.0755\n",
      "2020-07-18 11:07:55,839 best threshold=-1.605277, f1=0.4690\n",
      "2020-07-18 11:08:04,765 using threshold -1.6053\n",
      "2020-07-18 11:08:05,206 test_loss: 0.5246 AUC: 0.6841 Prec: 0.3397 Rec: 0.7506 F1: 0.4678\n",
      "2020-07-18 11:08:06,060 train loss in this epoch 0.513777\n",
      "2020-07-18 11:08:06,944 train loss in this epoch 0.514294\n",
      "2020-07-18 11:08:07,807 train loss in this epoch 0.513693\n",
      "2020-07-18 11:08:08,682 train loss in this epoch 0.512274\n",
      "2020-07-18 11:08:09,538 train loss in this epoch 0.511559\n",
      "2020-07-18 11:08:10,416 train loss in this epoch 0.512844\n",
      "2020-07-18 11:08:11,323 train loss in this epoch 0.512451\n",
      "2020-07-18 11:08:12,313 train loss in this epoch 0.511925\n",
      "2020-07-18 11:08:13,192 train loss in this epoch 0.512262\n",
      "2020-07-18 11:08:14,083 train loss in this epoch 0.512823\n",
      "2020-07-18 11:08:14,086 epoch 49, checkpoint!\n",
      "2020-07-18 11:09:21,269 valid_loss: 0.5230 AUC: 0.6870 Prec: 0.5257 Rec: 0.0461 F1: 0.0848\n",
      "2020-07-18 11:09:21,840 best threshold=-1.611804, f1=0.4701\n",
      "2020-07-18 11:09:30,553 using threshold -1.6118\n",
      "2020-07-18 11:09:30,861 test_loss: 0.5235 AUC: 0.6864 Prec: 0.3408 Rec: 0.7556 F1: 0.4697\n",
      "2020-07-18 11:09:31,735 train loss in this epoch 0.511990\n",
      "2020-07-18 11:09:32,610 train loss in this epoch 0.511751\n",
      "2020-07-18 11:09:33,490 train loss in this epoch 0.510755\n",
      "2020-07-18 11:09:34,373 train loss in this epoch 0.509414\n",
      "2020-07-18 11:09:35,285 train loss in this epoch 0.508414\n",
      "2020-07-18 11:09:36,151 train loss in this epoch 0.509487\n",
      "2020-07-18 11:09:37,019 train loss in this epoch 0.510957\n",
      "2020-07-18 11:09:37,921 train loss in this epoch 0.510557\n",
      "2020-07-18 11:09:38,814 train loss in this epoch 0.509821\n",
      "2020-07-18 11:09:39,713 train loss in this epoch 0.511278\n",
      "2020-07-18 11:09:39,715 epoch 59, checkpoint!\n",
      "2020-07-18 11:10:44,694 valid_loss: 0.5215 AUC: 0.6887 Prec: 0.5280 Rec: 0.0594 F1: 0.1068\n",
      "2020-07-18 11:10:45,265 best threshold=-1.554119, f1=0.4712\n",
      "2020-07-18 11:10:54,040 using threshold -1.5541\n",
      "2020-07-18 11:10:54,446 test_loss: 0.5219 AUC: 0.6881 Prec: 0.3447 Rec: 0.7408 F1: 0.4704\n",
      "2020-07-18 11:10:55,352 train loss in this epoch 0.509913\n",
      "2020-07-18 11:10:56,256 train loss in this epoch 0.511034\n",
      "2020-07-18 11:10:57,128 train loss in this epoch 0.509242\n",
      "2020-07-18 11:10:57,997 train loss in this epoch 0.508294\n",
      "2020-07-18 11:10:58,872 train loss in this epoch 0.507861\n",
      "2020-07-18 11:10:59,721 train loss in this epoch 0.508763\n",
      "2020-07-18 11:11:00,571 train loss in this epoch 0.509104\n",
      "2020-07-18 11:11:01,482 train loss in this epoch 0.508900\n",
      "2020-07-18 11:11:02,372 train loss in this epoch 0.508350\n",
      "2020-07-18 11:11:03,354 train loss in this epoch 0.508961\n",
      "2020-07-18 11:11:03,357 epoch 69, checkpoint!\n",
      "2020-07-18 11:12:09,351 valid_loss: 0.5214 AUC: 0.6904 Prec: 0.5320 Rec: 0.0582 F1: 0.1049\n",
      "2020-07-18 11:12:09,917 best threshold=-1.596703, f1=0.4721\n",
      "2020-07-18 11:12:18,207 using threshold -1.5967\n",
      "2020-07-18 11:12:18,709 test_loss: 0.5218 AUC: 0.6900 Prec: 0.3448 Rec: 0.7476 F1: 0.4720\n",
      "2020-07-18 11:12:19,602 train loss in this epoch 0.508843\n",
      "2020-07-18 11:12:20,457 train loss in this epoch 0.506827\n",
      "2020-07-18 11:12:21,343 train loss in this epoch 0.505900\n",
      "2020-07-18 11:12:22,234 train loss in this epoch 0.507033\n",
      "2020-07-18 11:12:23,090 train loss in this epoch 0.508006\n",
      "2020-07-18 11:12:23,953 train loss in this epoch 0.508448\n",
      "2020-07-18 11:12:24,826 train loss in this epoch 0.507634\n",
      "2020-07-18 11:12:25,701 train loss in this epoch 0.507128\n",
      "2020-07-18 11:12:26,576 train loss in this epoch 0.506524\n",
      "2020-07-18 11:12:27,481 train loss in this epoch 0.507399\n",
      "2020-07-18 11:12:27,484 epoch 79, checkpoint!\n",
      "2020-07-18 11:13:34,134 valid_loss: 0.5199 AUC: 0.6920 Prec: 0.5316 Rec: 0.0716 F1: 0.1263\n",
      "2020-07-18 11:13:34,709 best threshold=-1.557503, f1=0.4729\n",
      "2020-07-18 11:13:43,489 using threshold -1.5575\n",
      "2020-07-18 11:13:44,093 test_loss: 0.5203 AUC: 0.6915 Prec: 0.3456 Rec: 0.7432 F1: 0.4718\n",
      "2020-07-18 11:13:45,002 train loss in this epoch 0.506435\n",
      "2020-07-18 11:13:45,912 train loss in this epoch 0.506726\n",
      "2020-07-18 11:13:46,785 train loss in this epoch 0.507751\n",
      "2020-07-18 11:13:47,669 train loss in this epoch 0.506910\n",
      "2020-07-18 11:13:48,548 train loss in this epoch 0.507850\n",
      "2020-07-18 11:13:49,406 train loss in this epoch 0.506083\n",
      "2020-07-18 11:13:50,289 train loss in this epoch 0.505271\n",
      "2020-07-18 11:13:51,143 train loss in this epoch 0.503679\n",
      "2020-07-18 11:13:52,005 train loss in this epoch 0.506028\n",
      "2020-07-18 11:13:52,882 train loss in this epoch 0.505803\n",
      "2020-07-18 11:13:52,884 epoch 89, checkpoint!\n",
      "2020-07-18 11:14:59,716 valid_loss: 0.5194 AUC: 0.6937 Prec: 0.5356 Rec: 0.0701 F1: 0.1240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-18 11:15:00,281 best threshold=-1.554631, f1=0.4740\n",
      "2020-07-18 11:15:09,347 using threshold -1.5546\n",
      "2020-07-18 11:15:09,705 test_loss: 0.5199 AUC: 0.6931 Prec: 0.3494 Rec: 0.7357 F1: 0.4738\n",
      "2020-07-18 11:15:10,579 train loss in this epoch 0.505811\n",
      "2020-07-18 11:15:11,689 train loss in this epoch 0.505841\n",
      "2020-07-18 11:15:12,601 train loss in this epoch 0.506164\n",
      "2020-07-18 11:15:13,455 train loss in this epoch 0.506660\n",
      "2020-07-18 11:15:14,305 train loss in this epoch 0.506348\n",
      "2020-07-18 11:15:15,157 train loss in this epoch 0.504176\n",
      "2020-07-18 11:15:16,031 train loss in this epoch 0.504163\n",
      "2020-07-18 11:15:16,938 train loss in this epoch 0.505757\n",
      "2020-07-18 11:15:17,817 train loss in this epoch 0.505464\n",
      "2020-07-18 11:15:18,686 train loss in this epoch 0.504610\n",
      "2020-07-18 11:15:18,688 epoch 99, checkpoint!\n",
      "2020-07-18 11:16:24,185 valid_loss: 0.5185 AUC: 0.6948 Prec: 0.5340 Rec: 0.0819 F1: 0.1421\n",
      "2020-07-18 11:16:24,755 best threshold=-1.514119, f1=0.4748\n",
      "2020-07-18 11:16:34,179 using threshold -1.5141\n",
      "2020-07-18 11:16:34,625 test_loss: 0.5190 AUC: 0.6941 Prec: 0.3525 Rec: 0.7254 F1: 0.4744\n",
      "2020-07-18 11:16:35,482 train loss in this epoch 0.502562\n",
      "2020-07-18 11:16:36,351 train loss in this epoch 0.503302\n",
      "2020-07-18 11:16:37,210 train loss in this epoch 0.503170\n",
      "2020-07-18 11:16:38,081 train loss in this epoch 0.504725\n",
      "2020-07-18 11:16:38,957 train loss in this epoch 0.504426\n",
      "2020-07-18 11:16:39,849 train loss in this epoch 0.502481\n",
      "2020-07-18 11:16:40,754 train loss in this epoch 0.503368\n",
      "2020-07-18 11:16:41,646 train loss in this epoch 0.502694\n",
      "2020-07-18 11:16:42,538 train loss in this epoch 0.502403\n",
      "2020-07-18 11:16:43,432 train loss in this epoch 0.502357\n",
      "2020-07-18 11:16:43,434 epoch 109, checkpoint!\n",
      "2020-07-18 11:17:49,689 valid_loss: 0.5185 AUC: 0.6961 Prec: 0.5423 Rec: 0.0777 F1: 0.1359\n",
      "2020-07-18 11:17:50,259 best threshold=-1.544088, f1=0.4755\n",
      "2020-07-18 11:17:58,969 using threshold -1.5441\n",
      "2020-07-18 11:17:59,414 test_loss: 0.5189 AUC: 0.6955 Prec: 0.3537 Rec: 0.7249 F1: 0.4754\n",
      "2020-07-18 11:18:00,322 train loss in this epoch 0.503273\n",
      "2020-07-18 11:18:01,190 train loss in this epoch 0.503240\n",
      "2020-07-18 11:18:02,075 train loss in this epoch 0.504093\n",
      "2020-07-18 11:18:02,956 train loss in this epoch 0.503163\n",
      "2020-07-18 11:18:03,857 train loss in this epoch 0.503136\n",
      "2020-07-18 11:18:04,762 train loss in this epoch 0.502937\n",
      "2020-07-18 11:18:05,636 train loss in this epoch 0.502945\n",
      "2020-07-18 11:18:06,510 train loss in this epoch 0.502233\n",
      "2020-07-18 11:18:07,390 train loss in this epoch 0.503891\n",
      "2020-07-18 11:18:08,284 train loss in this epoch 0.502405\n",
      "2020-07-18 11:18:08,285 epoch 119, checkpoint!\n",
      "2020-07-18 11:19:13,616 valid_loss: 0.5183 AUC: 0.6975 Prec: 0.5466 Rec: 0.0738 F1: 0.1301\n",
      "2020-07-18 11:19:14,189 best threshold=-1.561366, f1=0.4765\n",
      "2020-07-18 11:19:23,736 using threshold -1.5614\n",
      "2020-07-18 11:19:24,150 test_loss: 0.5188 AUC: 0.6968 Prec: 0.3546 Rec: 0.7251 F1: 0.4763\n",
      "2020-07-18 11:19:25,009 train loss in this epoch 0.502150\n",
      "2020-07-18 11:19:25,862 train loss in this epoch 0.501985\n",
      "2020-07-18 11:19:26,739 train loss in this epoch 0.501794\n",
      "2020-07-18 11:19:27,613 train loss in this epoch 0.500045\n",
      "2020-07-18 11:19:28,553 train loss in this epoch 0.500361\n",
      "2020-07-18 11:19:29,519 train loss in this epoch 0.501544\n",
      "2020-07-18 11:19:30,366 train loss in this epoch 0.500339\n",
      "2020-07-18 11:19:31,324 train loss in this epoch 0.500667\n",
      "2020-07-18 11:19:32,324 train loss in this epoch 0.500709\n",
      "2020-07-18 11:19:33,297 train loss in this epoch 0.501364\n",
      "2020-07-18 11:19:33,299 epoch 129, checkpoint!\n",
      "2020-07-18 11:20:38,610 valid_loss: 0.5176 AUC: 0.6987 Prec: 0.5468 Rec: 0.0828 F1: 0.1438\n",
      "2020-07-18 11:20:39,179 best threshold=-1.562181, f1=0.4771\n",
      "2020-07-18 11:20:47,361 using threshold -1.5622\n",
      "2020-07-18 11:20:47,701 test_loss: 0.5181 AUC: 0.6979 Prec: 0.3540 Rec: 0.7305 F1: 0.4769\n",
      "2020-07-18 11:20:48,580 train loss in this epoch 0.501101\n",
      "2020-07-18 11:20:49,445 train loss in this epoch 0.501720\n",
      "2020-07-18 11:20:50,322 train loss in this epoch 0.501466\n",
      "2020-07-18 11:20:51,200 train loss in this epoch 0.501993\n",
      "2020-07-18 11:20:52,302 train loss in this epoch 0.501599\n",
      "2020-07-18 11:20:53,168 train loss in this epoch 0.502009\n",
      "2020-07-18 11:20:54,061 train loss in this epoch 0.501722\n",
      "2020-07-18 11:20:54,923 train loss in this epoch 0.500798\n",
      "2020-07-18 11:20:55,827 train loss in this epoch 0.499066\n",
      "2020-07-18 11:20:56,703 train loss in this epoch 0.499531\n",
      "2020-07-18 11:20:56,705 epoch 139, checkpoint!\n",
      "2020-07-18 11:22:02,687 valid_loss: 0.5164 AUC: 0.6995 Prec: 0.5396 Rec: 0.0968 F1: 0.1641\n",
      "2020-07-18 11:22:03,254 best threshold=-1.528480, f1=0.4777\n",
      "2020-07-18 11:22:12,190 using threshold -1.5285\n",
      "2020-07-18 11:22:12,703 test_loss: 0.5170 AUC: 0.6986 Prec: 0.3538 Rec: 0.7314 F1: 0.4769\n",
      "2020-07-18 11:22:13,595 train loss in this epoch 0.500118\n",
      "2020-07-18 11:22:14,455 train loss in this epoch 0.500352\n",
      "2020-07-18 11:22:15,307 train loss in this epoch 0.499859\n",
      "2020-07-18 11:22:16,175 train loss in this epoch 0.498782\n",
      "2020-07-18 11:22:17,056 train loss in this epoch 0.499879\n",
      "2020-07-18 11:22:17,949 train loss in this epoch 0.499587\n",
      "2020-07-18 11:22:18,855 train loss in this epoch 0.498815\n",
      "2020-07-18 11:22:19,723 train loss in this epoch 0.499218\n",
      "2020-07-18 11:22:20,590 train loss in this epoch 0.500689\n",
      "2020-07-18 11:22:21,459 train loss in this epoch 0.499326\n",
      "2020-07-18 11:22:21,460 epoch 149, checkpoint!\n",
      "2020-07-18 11:23:27,595 valid_loss: 0.5164 AUC: 0.7006 Prec: 0.5472 Rec: 0.0881 F1: 0.1518\n",
      "2020-07-18 11:23:28,160 best threshold=-1.530861, f1=0.4786\n",
      "2020-07-18 11:23:37,161 using threshold -1.5309\n",
      "2020-07-18 11:23:37,607 test_loss: 0.5170 AUC: 0.6998 Prec: 0.3587 Rec: 0.7158 F1: 0.4779\n",
      "2020-07-18 11:23:38,506 train loss in this epoch 0.498777\n",
      "2020-07-18 11:23:39,432 train loss in this epoch 0.497447\n",
      "2020-07-18 11:23:40,441 train loss in this epoch 0.497307\n",
      "2020-07-18 11:23:41,313 train loss in this epoch 0.499382\n",
      "2020-07-18 11:23:42,189 train loss in this epoch 0.500375\n",
      "2020-07-18 11:23:43,079 train loss in this epoch 0.498056\n",
      "2020-07-18 11:23:43,950 train loss in this epoch 0.500653\n",
      "2020-07-18 11:23:44,839 train loss in this epoch 0.499812\n",
      "2020-07-18 11:23:45,736 train loss in this epoch 0.499397\n",
      "2020-07-18 11:23:46,618 train loss in this epoch 0.499670\n",
      "2020-07-18 11:23:46,620 epoch 159, checkpoint!\n",
      "2020-07-18 11:24:51,247 valid_loss: 0.5157 AUC: 0.7015 Prec: 0.5457 Rec: 0.0965 F1: 0.1640\n",
      "2020-07-18 11:24:51,812 best threshold=-1.494419, f1=0.4792\n",
      "2020-07-18 11:25:01,662 using threshold -1.4944\n",
      "2020-07-18 11:25:01,906 test_loss: 0.5163 AUC: 0.7005 Prec: 0.3621 Rec: 0.7046 F1: 0.4784\n",
      "2020-07-18 11:25:02,786 train loss in this epoch 0.498177\n",
      "2020-07-18 11:25:03,690 train loss in this epoch 0.498957\n",
      "2020-07-18 11:25:04,599 train loss in this epoch 0.498041\n",
      "2020-07-18 11:25:05,508 train loss in this epoch 0.498475\n",
      "2020-07-18 11:25:06,378 train loss in this epoch 0.498024\n",
      "2020-07-18 11:25:07,258 train loss in this epoch 0.499240\n",
      "2020-07-18 11:25:08,159 train loss in this epoch 0.499690\n",
      "2020-07-18 11:25:09,118 train loss in this epoch 0.498746\n",
      "2020-07-18 11:25:10,044 train loss in this epoch 0.499305\n",
      "2020-07-18 11:25:10,930 train loss in this epoch 0.496799\n",
      "2020-07-18 11:25:10,931 epoch 169, checkpoint!\n",
      "2020-07-18 11:26:16,327 valid_loss: 0.5152 AUC: 0.7022 Prec: 0.5442 Rec: 0.1038 F1: 0.1744\n",
      "2020-07-18 11:26:16,899 best threshold=-1.508402, f1=0.4796\n",
      "2020-07-18 11:26:26,139 using threshold -1.5084\n",
      "2020-07-18 11:26:26,475 test_loss: 0.5158 AUC: 0.7012 Prec: 0.3593 Rec: 0.7195 F1: 0.4793\n",
      "2020-07-18 11:26:27,368 train loss in this epoch 0.496679\n",
      "2020-07-18 11:26:28,240 train loss in this epoch 0.496603\n",
      "2020-07-18 11:26:29,095 train loss in this epoch 0.497661\n",
      "2020-07-18 11:26:29,981 train loss in this epoch 0.497075\n",
      "2020-07-18 11:26:30,871 train loss in this epoch 0.496926\n",
      "2020-07-18 11:26:31,955 train loss in this epoch 0.497526\n",
      "2020-07-18 11:26:32,848 train loss in this epoch 0.496341\n",
      "2020-07-18 11:26:33,711 train loss in this epoch 0.497582\n",
      "2020-07-18 11:26:34,556 train loss in this epoch 0.497887\n",
      "2020-07-18 11:26:35,424 train loss in this epoch 0.495596\n",
      "2020-07-18 11:26:35,426 epoch 179, checkpoint!\n",
      "2020-07-18 11:27:44,612 valid_loss: 0.5149 AUC: 0.7031 Prec: 0.5475 Rec: 0.1028 F1: 0.1731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-18 11:27:45,185 best threshold=-1.528112, f1=0.4802\n",
      "2020-07-18 11:27:54,233 using threshold -1.5281\n",
      "2020-07-18 11:27:54,700 test_loss: 0.5156 AUC: 0.7020 Prec: 0.3582 Rec: 0.7260 F1: 0.4797\n",
      "2020-07-18 11:27:55,572 train loss in this epoch 0.496845\n",
      "2020-07-18 11:27:56,463 train loss in this epoch 0.497710\n",
      "2020-07-18 11:27:57,371 train loss in this epoch 0.495640\n",
      "2020-07-18 11:27:58,257 train loss in this epoch 0.496198\n",
      "2020-07-18 11:27:59,131 train loss in this epoch 0.497632\n",
      "2020-07-18 11:28:00,039 train loss in this epoch 0.497720\n",
      "2020-07-18 11:28:00,971 train loss in this epoch 0.496301\n",
      "2020-07-18 11:28:01,841 train loss in this epoch 0.495709\n",
      "2020-07-18 11:28:02,700 train loss in this epoch 0.496304\n",
      "2020-07-18 11:28:03,559 train loss in this epoch 0.495730\n",
      "2020-07-18 11:28:03,561 epoch 189, checkpoint!\n",
      "2020-07-18 11:29:10,703 valid_loss: 0.5151 AUC: 0.7038 Prec: 0.5511 Rec: 0.0984 F1: 0.1669\n",
      "2020-07-18 11:29:11,268 best threshold=-1.529049, f1=0.4809\n",
      "2020-07-18 11:29:20,680 using threshold -1.5290\n",
      "2020-07-18 11:29:21,202 test_loss: 0.5158 AUC: 0.7026 Prec: 0.3616 Rec: 0.7145 F1: 0.4802\n",
      "2020-07-18 11:29:22,092 train loss in this epoch 0.497025\n",
      "2020-07-18 11:29:22,968 train loss in this epoch 0.495604\n",
      "2020-07-18 11:29:23,839 train loss in this epoch 0.496260\n",
      "2020-07-18 11:29:24,696 train loss in this epoch 0.495417\n",
      "2020-07-18 11:29:25,597 train loss in this epoch 0.495744\n",
      "2020-07-18 11:29:26,483 train loss in this epoch 0.495995\n",
      "2020-07-18 11:29:27,373 train loss in this epoch 0.495006\n",
      "2020-07-18 11:29:28,260 train loss in this epoch 0.496525\n",
      "2020-07-18 11:29:29,165 train loss in this epoch 0.495753\n",
      "2020-07-18 11:29:30,041 train loss in this epoch 0.493862\n",
      "2020-07-18 11:29:30,044 epoch 199, checkpoint!\n",
      "2020-07-18 11:30:35,210 valid_loss: 0.5153 AUC: 0.7045 Prec: 0.5568 Rec: 0.0952 F1: 0.1626\n",
      "2020-07-18 11:30:35,776 best threshold=-1.552220, f1=0.4811\n",
      "2020-07-18 11:30:43,938 using threshold -1.5522\n",
      "2020-07-18 11:30:44,390 test_loss: 0.5161 AUC: 0.7034 Prec: 0.3620 Rec: 0.7140 F1: 0.4804\n",
      "2020-07-18 11:30:45,273 train loss in this epoch 0.496080\n",
      "2020-07-18 11:30:46,130 train loss in this epoch 0.495983\n",
      "2020-07-18 11:30:46,985 train loss in this epoch 0.495969\n",
      "2020-07-18 11:30:47,866 train loss in this epoch 0.495938\n",
      "2020-07-18 11:30:48,724 train loss in this epoch 0.496656\n",
      "2020-07-18 11:30:49,587 train loss in this epoch 0.495512\n",
      "2020-07-18 11:30:50,428 train loss in this epoch 0.494489\n",
      "2020-07-18 11:30:51,280 train loss in this epoch 0.495303\n",
      "2020-07-18 11:30:52,277 train loss in this epoch 0.495434\n",
      "2020-07-18 11:30:53,150 train loss in this epoch 0.493134\n",
      "2020-07-18 11:30:53,153 epoch 209, checkpoint!\n",
      "2020-07-18 11:31:59,211 valid_loss: 0.5144 AUC: 0.7052 Prec: 0.5538 Rec: 0.1047 F1: 0.1762\n",
      "2020-07-18 11:31:59,777 best threshold=-1.511178, f1=0.4816\n",
      "2020-07-18 11:32:08,562 using threshold -1.5112\n",
      "2020-07-18 11:32:09,149 test_loss: 0.5152 AUC: 0.7039 Prec: 0.3645 Rec: 0.7044 F1: 0.4804\n",
      "2020-07-18 11:32:10,022 train loss in this epoch 0.495495\n",
      "2020-07-18 11:32:10,887 train loss in this epoch 0.497106\n",
      "2020-07-18 11:32:11,775 train loss in this epoch 0.495240\n",
      "2020-07-18 11:32:12,724 train loss in this epoch 0.494092\n",
      "2020-07-18 11:32:13,596 train loss in this epoch 0.493943\n",
      "2020-07-18 11:32:14,496 train loss in this epoch 0.493868\n",
      "2020-07-18 11:32:15,480 train loss in this epoch 0.494511\n",
      "2020-07-18 11:32:16,374 train loss in this epoch 0.495115\n",
      "2020-07-18 11:32:17,487 train loss in this epoch 0.494398\n",
      "2020-07-18 11:32:18,378 train loss in this epoch 0.492785\n",
      "2020-07-18 11:32:18,379 epoch 219, checkpoint!\n",
      "2020-07-18 11:33:24,797 valid_loss: 0.5139 AUC: 0.7059 Prec: 0.5537 Rec: 0.1070 F1: 0.1793\n",
      "2020-07-18 11:33:25,370 best threshold=-1.525869, f1=0.4822\n",
      "2020-07-18 11:33:34,168 using threshold -1.5259\n",
      "2020-07-18 11:33:34,692 test_loss: 0.5146 AUC: 0.7047 Prec: 0.3624 Rec: 0.7161 F1: 0.4813\n",
      "2020-07-18 11:33:35,595 train loss in this epoch 0.495260\n",
      "2020-07-18 11:33:36,479 train loss in this epoch 0.493507\n",
      "2020-07-18 11:33:37,456 train loss in this epoch 0.493909\n",
      "2020-07-18 11:33:38,358 train loss in this epoch 0.493901\n",
      "2020-07-18 11:33:39,271 train loss in this epoch 0.492887\n",
      "2020-07-18 11:33:40,150 train loss in this epoch 0.495146\n",
      "2020-07-18 11:33:41,005 train loss in this epoch 0.491892\n",
      "2020-07-18 11:33:41,866 train loss in this epoch 0.491802\n",
      "2020-07-18 11:33:42,743 train loss in this epoch 0.492216\n",
      "2020-07-18 11:33:43,626 train loss in this epoch 0.495034\n",
      "2020-07-18 11:33:43,628 epoch 229, checkpoint!\n",
      "2020-07-18 11:34:48,683 valid_loss: 0.5143 AUC: 0.7064 Prec: 0.5558 Rec: 0.1035 F1: 0.1745\n",
      "2020-07-18 11:34:49,256 best threshold=-1.558398, f1=0.4826\n",
      "2020-07-18 11:34:58,941 using threshold -1.5584\n",
      "2020-07-18 11:34:59,334 test_loss: 0.5151 AUC: 0.7052 Prec: 0.3610 Rec: 0.7213 F1: 0.4812\n",
      "2020-07-18 11:35:00,337 train loss in this epoch 0.494833\n",
      "2020-07-18 11:35:01,274 train loss in this epoch 0.495329\n",
      "2020-07-18 11:35:02,216 train loss in this epoch 0.492854\n",
      "2020-07-18 11:35:03,218 train loss in this epoch 0.491630\n",
      "2020-07-18 11:35:04,211 train loss in this epoch 0.493509\n",
      "2020-07-18 11:35:05,127 train loss in this epoch 0.494073\n",
      "2020-07-18 11:35:06,019 train loss in this epoch 0.491550\n",
      "2020-07-18 11:35:06,929 train loss in this epoch 0.494422\n",
      "2020-07-18 11:35:07,818 train loss in this epoch 0.490752\n",
      "2020-07-18 11:35:08,720 train loss in this epoch 0.490870\n",
      "2020-07-18 11:35:08,722 epoch 239, checkpoint!\n",
      "2020-07-18 11:36:16,114 valid_loss: 0.5132 AUC: 0.7069 Prec: 0.5505 Rec: 0.1171 F1: 0.1931\n",
      "2020-07-18 11:36:16,682 best threshold=-1.489037, f1=0.4829\n",
      "2020-07-18 11:36:26,308 using threshold -1.4890\n",
      "2020-07-18 11:36:26,680 test_loss: 0.5141 AUC: 0.7056 Prec: 0.3660 Rec: 0.7033 F1: 0.4814\n",
      "2020-07-18 11:36:27,574 train loss in this epoch 0.492096\n",
      "2020-07-18 11:36:28,477 train loss in this epoch 0.493214\n",
      "2020-07-18 11:36:29,348 train loss in this epoch 0.495706\n",
      "2020-07-18 11:36:30,222 train loss in this epoch 0.493903\n",
      "2020-07-18 11:36:31,147 train loss in this epoch 0.492548\n",
      "2020-07-18 11:36:32,068 train loss in this epoch 0.492736\n",
      "2020-07-18 11:36:32,953 train loss in this epoch 0.491951\n",
      "2020-07-18 11:36:33,874 train loss in this epoch 0.491622\n",
      "2020-07-18 11:36:34,900 train loss in this epoch 0.491589\n",
      "2020-07-18 11:36:35,958 train loss in this epoch 0.491185\n",
      "2020-07-18 11:36:35,960 epoch 249, checkpoint!\n",
      "2020-07-18 11:37:43,236 valid_loss: 0.5132 AUC: 0.7074 Prec: 0.5538 Rec: 0.1149 F1: 0.1903\n",
      "2020-07-18 11:37:43,800 best threshold=-1.532210, f1=0.4832\n",
      "2020-07-18 11:37:52,507 using threshold -1.5322\n",
      "2020-07-18 11:37:52,944 test_loss: 0.5141 AUC: 0.7061 Prec: 0.3623 Rec: 0.7201 F1: 0.4821\n",
      "2020-07-18 11:37:53,850 train loss in this epoch 0.492800\n",
      "2020-07-18 11:37:54,738 train loss in this epoch 0.493691\n",
      "2020-07-18 11:37:55,615 train loss in this epoch 0.491934\n",
      "2020-07-18 11:37:56,526 train loss in this epoch 0.491219\n",
      "2020-07-18 11:37:57,442 train loss in this epoch 0.494049\n",
      "2020-07-18 11:37:58,317 train loss in this epoch 0.493245\n",
      "2020-07-18 11:37:59,206 train loss in this epoch 0.492330\n",
      "2020-07-18 11:38:00,131 train loss in this epoch 0.490652\n",
      "2020-07-18 11:38:01,027 train loss in this epoch 0.491070\n",
      "2020-07-18 11:38:02,109 train loss in this epoch 0.492441\n",
      "2020-07-18 11:38:02,111 epoch 259, checkpoint!\n",
      "2020-07-18 11:39:08,123 valid_loss: 0.5131 AUC: 0.7081 Prec: 0.5574 Rec: 0.1128 F1: 0.1877\n",
      "2020-07-18 11:39:08,691 best threshold=-1.539306, f1=0.4837\n",
      "2020-07-18 11:39:17,987 using threshold -1.5393\n",
      "2020-07-18 11:39:18,485 test_loss: 0.5140 AUC: 0.7067 Prec: 0.3639 Rec: 0.7180 F1: 0.4829\n",
      "2020-07-18 11:39:19,377 train loss in this epoch 0.493864\n",
      "2020-07-18 11:39:20,240 train loss in this epoch 0.490541\n",
      "2020-07-18 11:39:21,149 train loss in this epoch 0.491482\n",
      "2020-07-18 11:39:22,037 train loss in this epoch 0.489994\n",
      "2020-07-18 11:39:22,908 train loss in this epoch 0.491039\n",
      "2020-07-18 11:39:23,784 train loss in this epoch 0.490112\n",
      "2020-07-18 11:39:24,653 train loss in this epoch 0.491419\n",
      "2020-07-18 11:39:25,531 train loss in this epoch 0.493174\n",
      "2020-07-18 11:39:26,401 train loss in this epoch 0.492997\n",
      "2020-07-18 11:39:27,272 train loss in this epoch 0.488964\n",
      "2020-07-18 11:39:27,274 epoch 269, checkpoint!\n",
      "2020-07-18 11:40:35,558 valid_loss: 0.5125 AUC: 0.7085 Prec: 0.5536 Rec: 0.1191 F1: 0.1961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-18 11:40:36,130 best threshold=-1.525539, f1=0.4842\n",
      "2020-07-18 11:40:45,377 using threshold -1.5255\n",
      "2020-07-18 11:40:45,713 test_loss: 0.5134 AUC: 0.7071 Prec: 0.3636 Rec: 0.7202 F1: 0.4832\n",
      "2020-07-18 11:40:46,597 train loss in this epoch 0.490449\n",
      "2020-07-18 11:40:47,470 train loss in this epoch 0.491087\n",
      "2020-07-18 11:40:48,336 train loss in this epoch 0.490537\n",
      "2020-07-18 11:40:49,245 train loss in this epoch 0.490913\n",
      "2020-07-18 11:40:50,132 train loss in this epoch 0.491602\n",
      "2020-07-18 11:40:50,987 train loss in this epoch 0.491120\n",
      "2020-07-18 11:40:51,855 train loss in this epoch 0.491020\n",
      "2020-07-18 11:40:52,732 train loss in this epoch 0.490658\n",
      "2020-07-18 11:40:53,596 train loss in this epoch 0.488805\n",
      "2020-07-18 11:40:54,486 train loss in this epoch 0.489443\n",
      "2020-07-18 11:40:54,487 epoch 279, checkpoint!\n",
      "2020-07-18 11:42:00,619 valid_loss: 0.5125 AUC: 0.7092 Prec: 0.5599 Rec: 0.1176 F1: 0.1944\n",
      "2020-07-18 11:42:01,194 best threshold=-1.531608, f1=0.4846\n",
      "2020-07-18 11:42:10,265 using threshold -1.5316\n",
      "2020-07-18 11:42:10,509 test_loss: 0.5135 AUC: 0.7077 Prec: 0.3642 Rec: 0.7173 F1: 0.4831\n",
      "2020-07-18 11:42:11,400 train loss in this epoch 0.491731\n",
      "2020-07-18 11:42:12,241 train loss in this epoch 0.490890\n",
      "2020-07-18 11:42:13,152 train loss in this epoch 0.493185\n",
      "2020-07-18 11:42:14,030 train loss in this epoch 0.490948\n",
      "2020-07-18 11:42:14,892 train loss in this epoch 0.489600\n",
      "2020-07-18 11:42:15,792 train loss in this epoch 0.489280\n",
      "2020-07-18 11:42:16,765 train loss in this epoch 0.489452\n",
      "2020-07-18 11:42:17,628 train loss in this epoch 0.488954\n",
      "2020-07-18 11:42:18,532 train loss in this epoch 0.489972\n",
      "2020-07-18 11:42:19,433 train loss in this epoch 0.487834\n",
      "2020-07-18 11:42:19,435 epoch 289, checkpoint!\n",
      "2020-07-18 11:43:26,635 valid_loss: 0.5123 AUC: 0.7095 Prec: 0.5554 Rec: 0.1224 F1: 0.2006\n",
      "2020-07-18 11:43:27,203 best threshold=-1.522850, f1=0.4847\n",
      "2020-07-18 11:43:36,245 using threshold -1.5229\n",
      "2020-07-18 11:43:36,657 test_loss: 0.5133 AUC: 0.7080 Prec: 0.3651 Rec: 0.7168 F1: 0.4838\n",
      "2020-07-18 11:43:37,537 train loss in this epoch 0.490803\n",
      "2020-07-18 11:43:38,398 train loss in this epoch 0.490503\n",
      "2020-07-18 11:43:39,267 train loss in this epoch 0.490499\n",
      "2020-07-18 11:43:40,186 train loss in this epoch 0.490125\n",
      "2020-07-18 11:43:41,151 train loss in this epoch 0.490927\n",
      "2020-07-18 11:43:42,058 train loss in this epoch 0.488868\n",
      "2020-07-18 11:43:42,970 train loss in this epoch 0.488501\n",
      "2020-07-18 11:43:43,869 train loss in this epoch 0.489420\n",
      "2020-07-18 11:43:44,764 train loss in this epoch 0.490447\n",
      "2020-07-18 11:43:45,648 train loss in this epoch 0.490732\n",
      "2020-07-18 11:43:45,650 epoch 299, checkpoint!\n",
      "2020-07-18 11:44:52,001 valid_loss: 0.5124 AUC: 0.7099 Prec: 0.5621 Rec: 0.1165 F1: 0.1930\n",
      "2020-07-18 11:44:52,579 best threshold=-1.567369, f1=0.4849\n",
      "2020-07-18 11:45:01,794 using threshold -1.5674\n",
      "2020-07-18 11:45:02,192 test_loss: 0.5135 AUC: 0.7084 Prec: 0.3614 Rec: 0.7288 F1: 0.4832\n",
      "2020-07-18 11:45:03,084 train loss in this epoch 0.489982\n",
      "2020-07-18 11:45:03,967 train loss in this epoch 0.489860\n",
      "2020-07-18 11:45:04,882 train loss in this epoch 0.487024\n",
      "2020-07-18 11:45:05,786 train loss in this epoch 0.487814\n",
      "2020-07-18 11:45:06,676 train loss in this epoch 0.490171\n",
      "2020-07-18 11:45:07,575 train loss in this epoch 0.489406\n",
      "2020-07-18 11:45:08,533 train loss in this epoch 0.488543\n",
      "2020-07-18 11:45:09,438 train loss in this epoch 0.488178\n",
      "2020-07-18 11:45:10,311 train loss in this epoch 0.489947\n",
      "2020-07-18 11:45:11,185 train loss in this epoch 0.490027\n",
      "2020-07-18 11:45:11,187 epoch 309, checkpoint!\n",
      "2020-07-18 11:46:18,229 valid_loss: 0.5126 AUC: 0.7104 Prec: 0.5635 Rec: 0.1125 F1: 0.1876\n",
      "2020-07-18 11:46:18,793 best threshold=-1.560615, f1=0.4855\n",
      "2020-07-18 11:46:27,451 using threshold -1.5606\n",
      "2020-07-18 11:46:27,988 test_loss: 0.5137 AUC: 0.7089 Prec: 0.3653 Rec: 0.7177 F1: 0.4842\n",
      "2020-07-18 11:46:28,912 train loss in this epoch 0.490585\n",
      "2020-07-18 11:46:29,837 train loss in this epoch 0.487734\n",
      "2020-07-18 11:46:30,794 train loss in this epoch 0.487944\n",
      "2020-07-18 11:46:31,702 train loss in this epoch 0.489137\n",
      "2020-07-18 11:46:32,621 train loss in this epoch 0.490367\n",
      "2020-07-18 11:46:33,502 train loss in this epoch 0.488658\n",
      "2020-07-18 11:46:34,385 train loss in this epoch 0.490176\n",
      "2020-07-18 11:46:35,268 train loss in this epoch 0.487655\n",
      "2020-07-18 11:46:36,144 train loss in this epoch 0.487406\n",
      "2020-07-18 11:46:37,000 train loss in this epoch 0.489187\n",
      "2020-07-18 11:46:37,003 epoch 319, checkpoint!\n",
      "2020-07-18 11:47:42,554 valid_loss: 0.5118 AUC: 0.7105 Prec: 0.5556 Rec: 0.1277 F1: 0.2077\n",
      "2020-07-18 11:47:43,119 best threshold=-1.539386, f1=0.4855\n",
      "2020-07-18 11:47:51,750 using threshold -1.5394\n",
      "2020-07-18 11:47:51,994 test_loss: 0.5129 AUC: 0.7090 Prec: 0.3626 Rec: 0.7267 F1: 0.4838\n",
      "2020-07-18 11:47:52,863 train loss in this epoch 0.488601\n",
      "2020-07-18 11:47:53,749 train loss in this epoch 0.491485\n",
      "2020-07-18 11:47:54,717 train loss in this epoch 0.489906\n",
      "2020-07-18 11:47:55,649 train loss in this epoch 0.489973\n",
      "2020-07-18 11:47:56,551 train loss in this epoch 0.488593\n",
      "2020-07-18 11:47:57,442 train loss in this epoch 0.487570\n",
      "2020-07-18 11:47:58,332 train loss in this epoch 0.488445\n",
      "2020-07-18 11:47:59,205 train loss in this epoch 0.488587\n",
      "2020-07-18 11:48:00,097 train loss in this epoch 0.489704\n",
      "2020-07-18 11:48:00,982 train loss in this epoch 0.489160\n",
      "2020-07-18 11:48:00,984 epoch 329, checkpoint!\n",
      "2020-07-18 11:49:08,033 valid_loss: 0.5119 AUC: 0.7110 Prec: 0.5591 Rec: 0.1213 F1: 0.1994\n",
      "2020-07-18 11:49:08,598 best threshold=-1.540662, f1=0.4859\n",
      "2020-07-18 11:49:17,589 using threshold -1.5407\n",
      "2020-07-18 11:49:17,958 test_loss: 0.5129 AUC: 0.7094 Prec: 0.3657 Rec: 0.7185 F1: 0.4847\n",
      "2020-07-18 11:49:18,867 train loss in this epoch 0.488998\n",
      "2020-07-18 11:49:19,733 train loss in this epoch 0.486491\n",
      "2020-07-18 11:49:20,604 train loss in this epoch 0.488392\n",
      "2020-07-18 11:49:21,453 train loss in this epoch 0.487598\n",
      "2020-07-18 11:49:22,348 train loss in this epoch 0.488126\n",
      "2020-07-18 11:49:23,256 train loss in this epoch 0.487314\n",
      "2020-07-18 11:49:24,161 train loss in this epoch 0.488597\n",
      "2020-07-18 11:49:25,078 train loss in this epoch 0.487034\n",
      "2020-07-18 11:49:26,088 train loss in this epoch 0.487592\n",
      "2020-07-18 11:49:27,095 train loss in this epoch 0.489998\n",
      "2020-07-18 11:49:27,098 epoch 339, checkpoint!\n",
      "2020-07-18 11:50:33,655 valid_loss: 0.5119 AUC: 0.7113 Prec: 0.5603 Rec: 0.1203 F1: 0.1981\n",
      "2020-07-18 11:50:34,221 best threshold=-1.545818, f1=0.4861\n",
      "2020-07-18 11:50:43,190 using threshold -1.5458\n",
      "2020-07-18 11:50:43,577 test_loss: 0.5130 AUC: 0.7096 Prec: 0.3660 Rec: 0.7168 F1: 0.4846\n",
      "2020-07-18 11:50:44,450 train loss in this epoch 0.489980\n",
      "2020-07-18 11:50:45,341 train loss in this epoch 0.489279\n",
      "2020-07-18 11:50:46,235 train loss in this epoch 0.487761\n",
      "2020-07-18 11:50:47,112 train loss in this epoch 0.486458\n",
      "2020-07-18 11:50:47,989 train loss in this epoch 0.487024\n",
      "2020-07-18 11:50:48,842 train loss in this epoch 0.487249\n",
      "2020-07-18 11:50:49,707 train loss in this epoch 0.488474\n",
      "2020-07-18 11:50:50,568 train loss in this epoch 0.487136\n",
      "2020-07-18 11:50:51,465 train loss in this epoch 0.485794\n",
      "2020-07-18 11:50:52,366 train loss in this epoch 0.487335\n",
      "2020-07-18 11:50:52,368 epoch 349, checkpoint!\n",
      "2020-07-18 11:51:59,121 valid_loss: 0.5114 AUC: 0.7117 Prec: 0.5570 Rec: 0.1300 F1: 0.2108\n",
      "2020-07-18 11:51:59,692 best threshold=-1.507094, f1=0.4864\n",
      "2020-07-18 11:52:09,003 using threshold -1.5071\n",
      "2020-07-18 11:52:09,528 test_loss: 0.5125 AUC: 0.7101 Prec: 0.3692 Rec: 0.7074 F1: 0.4852\n",
      "2020-07-18 11:52:10,420 train loss in this epoch 0.488009\n",
      "2020-07-18 11:52:11,316 train loss in this epoch 0.488084\n",
      "2020-07-18 11:52:12,216 train loss in this epoch 0.487866\n",
      "2020-07-18 11:52:13,108 train loss in this epoch 0.488241\n",
      "2020-07-18 11:52:14,026 train loss in this epoch 0.488858\n",
      "2020-07-18 11:52:14,918 train loss in this epoch 0.489137\n",
      "2020-07-18 11:52:15,858 train loss in this epoch 0.487406\n",
      "2020-07-18 11:52:16,814 train loss in this epoch 0.486808\n",
      "2020-07-18 11:52:17,711 train loss in this epoch 0.489146\n",
      "2020-07-18 11:52:18,606 train loss in this epoch 0.488542\n",
      "2020-07-18 11:52:18,608 epoch 359, checkpoint!\n",
      "2020-07-18 11:53:25,616 valid_loss: 0.5114 AUC: 0.7120 Prec: 0.5604 Rec: 0.1244 F1: 0.2036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-18 11:53:26,181 best threshold=-1.528522, f1=0.4866\n",
      "2020-07-18 11:53:34,594 using threshold -1.5285\n",
      "2020-07-18 11:53:34,845 test_loss: 0.5125 AUC: 0.7104 Prec: 0.3677 Rec: 0.7118 F1: 0.4850\n",
      "2020-07-18 11:53:35,748 train loss in this epoch 0.487773\n",
      "2020-07-18 11:53:36,876 train loss in this epoch 0.486620\n",
      "2020-07-18 11:53:37,775 train loss in this epoch 0.487647\n",
      "2020-07-18 11:53:38,651 train loss in this epoch 0.487005\n",
      "2020-07-18 11:53:39,545 train loss in this epoch 0.487421\n",
      "2020-07-18 11:53:40,561 train loss in this epoch 0.488204\n",
      "2020-07-18 11:53:41,525 train loss in this epoch 0.486492\n",
      "2020-07-18 11:53:42,417 train loss in this epoch 0.488322\n",
      "2020-07-18 11:53:43,325 train loss in this epoch 0.485830\n",
      "2020-07-18 11:53:44,183 train loss in this epoch 0.486597\n",
      "2020-07-18 11:53:44,185 epoch 369, checkpoint!\n",
      "2020-07-18 11:54:52,103 valid_loss: 0.5114 AUC: 0.7122 Prec: 0.5616 Rec: 0.1235 F1: 0.2025\n",
      "2020-07-18 11:54:52,672 best threshold=-1.533478, f1=0.4867\n",
      "2020-07-18 11:55:01,203 using threshold -1.5335\n",
      "2020-07-18 11:55:01,593 test_loss: 0.5125 AUC: 0.7106 Prec: 0.3683 Rec: 0.7111 F1: 0.4853\n",
      "2020-07-18 11:55:02,484 train loss in this epoch 0.486443\n",
      "2020-07-18 11:55:03,379 train loss in this epoch 0.487894\n",
      "2020-07-18 11:55:04,241 train loss in this epoch 0.487557\n",
      "2020-07-18 11:55:05,144 train loss in this epoch 0.486858\n",
      "2020-07-18 11:55:06,039 train loss in this epoch 0.485752\n",
      "2020-07-18 11:55:06,920 train loss in this epoch 0.487083\n",
      "2020-07-18 11:55:07,826 train loss in this epoch 0.488776\n",
      "2020-07-18 11:55:08,718 train loss in this epoch 0.486815\n",
      "2020-07-18 11:55:09,599 train loss in this epoch 0.485408\n",
      "2020-07-18 11:55:10,485 train loss in this epoch 0.486379\n",
      "2020-07-18 11:55:10,486 epoch 379, checkpoint!\n",
      "2020-07-18 11:56:16,625 valid_loss: 0.5103 AUC: 0.7127 Prec: 0.5563 Rec: 0.1363 F1: 0.2189\n",
      "2020-07-18 11:56:17,192 best threshold=-1.496346, f1=0.4871\n",
      "2020-07-18 11:56:26,051 using threshold -1.4963\n",
      "2020-07-18 11:56:26,430 test_loss: 0.5115 AUC: 0.7110 Prec: 0.3687 Rec: 0.7119 F1: 0.4858\n",
      "2020-07-18 11:56:27,349 train loss in this epoch 0.487302\n",
      "2020-07-18 11:56:28,271 train loss in this epoch 0.487116\n",
      "2020-07-18 11:56:29,214 train loss in this epoch 0.485202\n",
      "2020-07-18 11:56:30,119 train loss in this epoch 0.487310\n",
      "2020-07-18 11:56:31,005 train loss in this epoch 0.487518\n",
      "2020-07-18 11:56:31,901 train loss in this epoch 0.485085\n",
      "2020-07-18 11:56:32,780 train loss in this epoch 0.488271\n",
      "2020-07-18 11:56:33,681 train loss in this epoch 0.486922\n",
      "2020-07-18 11:56:34,582 train loss in this epoch 0.485741\n",
      "2020-07-18 11:56:35,471 train loss in this epoch 0.486400\n",
      "2020-07-18 11:56:35,472 epoch 389, checkpoint!\n",
      "2020-07-18 11:57:43,563 valid_loss: 0.5109 AUC: 0.7129 Prec: 0.5600 Rec: 0.1288 F1: 0.2094\n",
      "2020-07-18 11:57:44,130 best threshold=-1.524382, f1=0.4874\n",
      "2020-07-18 11:57:53,923 using threshold -1.5244\n",
      "2020-07-18 11:57:54,334 test_loss: 0.5121 AUC: 0.7112 Prec: 0.3688 Rec: 0.7110 F1: 0.4857\n",
      "2020-07-18 11:57:55,358 train loss in this epoch 0.485766\n",
      "2020-07-18 11:57:56,290 train loss in this epoch 0.486289\n",
      "2020-07-18 11:57:57,315 train loss in this epoch 0.484295\n",
      "2020-07-18 11:57:58,308 train loss in this epoch 0.485894\n",
      "2020-07-18 11:57:59,216 train loss in this epoch 0.487143\n",
      "2020-07-18 11:58:00,108 train loss in this epoch 0.485070\n",
      "2020-07-18 11:58:00,981 train loss in this epoch 0.484409\n",
      "2020-07-18 11:58:01,876 train loss in this epoch 0.486413\n",
      "2020-07-18 11:58:02,754 train loss in this epoch 0.486776\n",
      "2020-07-18 11:58:03,633 train loss in this epoch 0.488484\n",
      "2020-07-18 11:58:03,635 epoch 399, checkpoint!\n",
      "2020-07-18 11:59:11,015 valid_loss: 0.5109 AUC: 0.7131 Prec: 0.5609 Rec: 0.1256 F1: 0.2053\n",
      "2020-07-18 11:59:11,580 best threshold=-1.519809, f1=0.4874\n",
      "2020-07-18 11:59:20,238 using threshold -1.5198\n",
      "2020-07-18 11:59:20,677 test_loss: 0.5121 AUC: 0.7114 Prec: 0.3702 Rec: 0.7045 F1: 0.4853\n",
      "2020-07-18 11:59:21,557 train loss in this epoch 0.485706\n",
      "2020-07-18 11:59:22,467 train loss in this epoch 0.485437\n",
      "2020-07-18 11:59:23,357 train loss in this epoch 0.485945\n",
      "2020-07-18 11:59:24,443 train loss in this epoch 0.487547\n",
      "2020-07-18 11:59:25,331 train loss in this epoch 0.484495\n",
      "2020-07-18 11:59:26,228 train loss in this epoch 0.485576\n",
      "2020-07-18 11:59:27,134 train loss in this epoch 0.484770\n",
      "2020-07-18 11:59:28,052 train loss in this epoch 0.484110\n",
      "2020-07-18 11:59:28,923 train loss in this epoch 0.484541\n",
      "2020-07-18 11:59:29,822 train loss in this epoch 0.484362\n",
      "2020-07-18 11:59:29,824 epoch 409, checkpoint!\n",
      "2020-07-18 12:00:35,488 valid_loss: 0.5103 AUC: 0.7135 Prec: 0.5615 Rec: 0.1332 F1: 0.2154\n",
      "2020-07-18 12:00:36,056 best threshold=-1.530002, f1=0.4876\n",
      "2020-07-18 12:00:45,033 using threshold -1.5300\n",
      "2020-07-18 12:00:45,421 test_loss: 0.5116 AUC: 0.7117 Prec: 0.3673 Rec: 0.7171 F1: 0.4857\n",
      "2020-07-18 12:00:46,328 train loss in this epoch 0.484208\n",
      "2020-07-18 12:00:47,221 train loss in this epoch 0.486888\n",
      "2020-07-18 12:00:48,109 train loss in this epoch 0.484623\n",
      "2020-07-18 12:00:48,960 train loss in this epoch 0.484343\n",
      "2020-07-18 12:00:49,838 train loss in this epoch 0.485749\n",
      "2020-07-18 12:00:50,746 train loss in this epoch 0.485583\n",
      "2020-07-18 12:00:51,664 train loss in this epoch 0.487591\n",
      "2020-07-18 12:00:52,553 train loss in this epoch 0.486443\n",
      "2020-07-18 12:00:53,465 train loss in this epoch 0.484115\n",
      "2020-07-18 12:00:54,418 train loss in this epoch 0.484608\n",
      "2020-07-18 12:00:54,419 epoch 419, checkpoint!\n",
      "2020-07-18 12:02:02,167 valid_loss: 0.5099 AUC: 0.7138 Prec: 0.5572 Rec: 0.1404 F1: 0.2243\n",
      "2020-07-18 12:02:02,735 best threshold=-1.498497, f1=0.4881\n",
      "2020-07-18 12:02:11,904 using threshold -1.4985\n",
      "2020-07-18 12:02:12,295 test_loss: 0.5111 AUC: 0.7120 Prec: 0.3690 Rec: 0.7111 F1: 0.4859\n",
      "2020-07-18 12:02:13,241 train loss in this epoch 0.485288\n",
      "2020-07-18 12:02:14,100 train loss in this epoch 0.484552\n",
      "2020-07-18 12:02:15,008 train loss in this epoch 0.486081\n",
      "2020-07-18 12:02:15,935 train loss in this epoch 0.486129\n",
      "2020-07-18 12:02:16,830 train loss in this epoch 0.485693\n",
      "2020-07-18 12:02:17,779 train loss in this epoch 0.484840\n",
      "2020-07-18 12:02:18,698 train loss in this epoch 0.486475\n",
      "2020-07-18 12:02:19,594 train loss in this epoch 0.484453\n",
      "2020-07-18 12:02:20,508 train loss in this epoch 0.485199\n",
      "2020-07-18 12:02:21,408 train loss in this epoch 0.484909\n",
      "2020-07-18 12:02:21,410 epoch 429, checkpoint!\n",
      "2020-07-18 12:03:27,732 valid_loss: 0.5105 AUC: 0.7140 Prec: 0.5655 Rec: 0.1289 F1: 0.2099\n",
      "2020-07-18 12:03:28,299 best threshold=-1.529810, f1=0.4879\n",
      "2020-07-18 12:03:37,236 using threshold -1.5298\n",
      "2020-07-18 12:03:37,613 test_loss: 0.5118 AUC: 0.7122 Prec: 0.3703 Rec: 0.7070 F1: 0.4860\n",
      "2020-07-18 12:03:38,515 train loss in this epoch 0.487042\n",
      "2020-07-18 12:03:39,411 train loss in this epoch 0.484605\n",
      "2020-07-18 12:03:40,317 train loss in this epoch 0.483509\n",
      "2020-07-18 12:03:41,231 train loss in this epoch 0.484432\n",
      "2020-07-18 12:03:42,151 train loss in this epoch 0.484738\n",
      "2020-07-18 12:03:43,031 train loss in this epoch 0.485271\n",
      "2020-07-18 12:03:43,914 train loss in this epoch 0.485728\n",
      "2020-07-18 12:03:44,810 train loss in this epoch 0.484834\n",
      "2020-07-18 12:03:45,717 train loss in this epoch 0.485825\n",
      "2020-07-18 12:03:46,601 train loss in this epoch 0.483157\n",
      "2020-07-18 12:03:46,604 epoch 439, checkpoint!\n",
      "2020-07-18 12:04:53,660 valid_loss: 0.5096 AUC: 0.7142 Prec: 0.5577 Rec: 0.1443 F1: 0.2292\n",
      "2020-07-18 12:04:54,232 best threshold=-1.492258, f1=0.4882\n",
      "2020-07-18 12:05:03,889 using threshold -1.4923\n",
      "2020-07-18 12:05:04,221 test_loss: 0.5109 AUC: 0.7124 Prec: 0.3697 Rec: 0.7124 F1: 0.4868\n",
      "2020-07-18 12:05:05,183 train loss in this epoch 0.484944\n",
      "2020-07-18 12:05:06,082 train loss in this epoch 0.485232\n",
      "2020-07-18 12:05:06,940 train loss in this epoch 0.484575\n",
      "2020-07-18 12:05:07,840 train loss in this epoch 0.485123\n",
      "2020-07-18 12:05:08,743 train loss in this epoch 0.484753\n",
      "2020-07-18 12:05:09,659 train loss in this epoch 0.483930\n",
      "2020-07-18 12:05:10,746 train loss in this epoch 0.483557\n",
      "2020-07-18 12:05:11,609 train loss in this epoch 0.483985\n",
      "2020-07-18 12:05:12,519 train loss in this epoch 0.485235\n",
      "2020-07-18 12:05:13,428 train loss in this epoch 0.484324\n",
      "2020-07-18 12:05:13,430 epoch 449, checkpoint!\n",
      "2020-07-18 12:06:20,220 valid_loss: 0.5098 AUC: 0.7145 Prec: 0.5608 Rec: 0.1360 F1: 0.2189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-18 12:06:20,787 best threshold=-1.509849, f1=0.4887\n",
      "2020-07-18 12:06:29,625 using threshold -1.5098\n",
      "2020-07-18 12:06:30,061 test_loss: 0.5111 AUC: 0.7128 Prec: 0.3713 Rec: 0.7081 F1: 0.4872\n",
      "2020-07-18 12:06:30,981 train loss in this epoch 0.483897\n",
      "2020-07-18 12:06:31,862 train loss in this epoch 0.486121\n",
      "2020-07-18 12:06:32,768 train loss in this epoch 0.484037\n",
      "2020-07-18 12:06:33,691 train loss in this epoch 0.483770\n",
      "2020-07-18 12:06:34,591 train loss in this epoch 0.483289\n",
      "2020-07-18 12:06:35,487 train loss in this epoch 0.483109\n",
      "2020-07-18 12:06:36,386 train loss in this epoch 0.485035\n",
      "2020-07-18 12:06:37,301 train loss in this epoch 0.482771\n",
      "2020-07-18 12:06:38,195 train loss in this epoch 0.484361\n",
      "2020-07-18 12:06:39,089 train loss in this epoch 0.483431\n",
      "2020-07-18 12:06:39,091 epoch 459, checkpoint!\n",
      "2020-07-18 12:07:47,234 valid_loss: 0.5094 AUC: 0.7148 Prec: 0.5596 Rec: 0.1458 F1: 0.2313\n",
      "2020-07-18 12:07:47,798 best threshold=-1.494785, f1=0.4885\n",
      "2020-07-18 12:07:56,913 using threshold -1.4948\n",
      "2020-07-18 12:07:57,214 test_loss: 0.5108 AUC: 0.7130 Prec: 0.3711 Rec: 0.7079 F1: 0.4869\n",
      "2020-07-18 12:07:58,106 train loss in this epoch 0.484656\n",
      "2020-07-18 12:07:59,007 train loss in this epoch 0.484386\n",
      "2020-07-18 12:07:59,942 train loss in this epoch 0.485104\n",
      "2020-07-18 12:08:00,842 train loss in this epoch 0.483911\n",
      "2020-07-18 12:08:01,737 train loss in this epoch 0.483993\n",
      "2020-07-18 12:08:02,616 train loss in this epoch 0.481739\n",
      "2020-07-18 12:08:03,514 train loss in this epoch 0.483341\n",
      "2020-07-18 12:08:04,466 train loss in this epoch 0.484102\n",
      "2020-07-18 12:08:05,358 train loss in this epoch 0.484209\n",
      "2020-07-18 12:08:06,262 train loss in this epoch 0.485765\n",
      "2020-07-18 12:08:06,263 epoch 469, checkpoint!\n",
      "2020-07-18 12:09:13,200 valid_loss: 0.5095 AUC: 0.7150 Prec: 0.5607 Rec: 0.1425 F1: 0.2272\n",
      "2020-07-18 12:09:13,768 best threshold=-1.497011, f1=0.4888\n",
      "2020-07-18 12:09:22,360 using threshold -1.4970\n",
      "2020-07-18 12:09:23,008 test_loss: 0.5108 AUC: 0.7131 Prec: 0.3717 Rec: 0.7079 F1: 0.4875\n",
      "2020-07-18 12:09:23,911 train loss in this epoch 0.484310\n",
      "2020-07-18 12:09:24,792 train loss in this epoch 0.485176\n",
      "2020-07-18 12:09:25,648 train loss in this epoch 0.484424\n",
      "2020-07-18 12:09:26,529 train loss in this epoch 0.484836\n",
      "2020-07-18 12:09:27,415 train loss in this epoch 0.484782\n",
      "2020-07-18 12:09:28,291 train loss in this epoch 0.482615\n",
      "2020-07-18 12:09:29,168 train loss in this epoch 0.480575\n",
      "2020-07-18 12:09:30,077 train loss in this epoch 0.484458\n",
      "2020-07-18 12:09:30,975 train loss in this epoch 0.485342\n",
      "2020-07-18 12:09:31,869 train loss in this epoch 0.484303\n",
      "2020-07-18 12:09:31,870 epoch 479, checkpoint!\n",
      "2020-07-18 12:10:40,190 valid_loss: 0.5093 AUC: 0.7152 Prec: 0.5607 Rec: 0.1435 F1: 0.2285\n",
      "2020-07-18 12:10:40,763 best threshold=-1.480990, f1=0.4890\n",
      "2020-07-18 12:10:50,123 using threshold -1.4810\n",
      "2020-07-18 12:10:50,368 test_loss: 0.5107 AUC: 0.7133 Prec: 0.3746 Rec: 0.6979 F1: 0.4875\n",
      "2020-07-18 12:10:51,316 train loss in this epoch 0.482999\n",
      "2020-07-18 12:10:52,187 train loss in this epoch 0.482819\n",
      "2020-07-18 12:10:53,071 train loss in this epoch 0.484355\n",
      "2020-07-18 12:10:53,954 train loss in this epoch 0.484280\n",
      "2020-07-18 12:10:54,815 train loss in this epoch 0.484257\n",
      "2020-07-18 12:10:55,676 train loss in this epoch 0.483376\n",
      "2020-07-18 12:10:56,590 train loss in this epoch 0.483452\n",
      "2020-07-18 12:10:57,505 train loss in this epoch 0.482912\n",
      "2020-07-18 12:10:58,606 train loss in this epoch 0.484763\n",
      "2020-07-18 12:10:59,526 train loss in this epoch 0.482390\n",
      "2020-07-18 12:10:59,528 epoch 489, checkpoint!\n",
      "2020-07-18 12:12:06,884 valid_loss: 0.5093 AUC: 0.7154 Prec: 0.5617 Rec: 0.1435 F1: 0.2286\n",
      "2020-07-18 12:12:07,452 best threshold=-1.496883, f1=0.4890\n",
      "2020-07-18 12:12:16,578 using threshold -1.4969\n",
      "2020-07-18 12:12:16,946 test_loss: 0.5107 AUC: 0.7135 Prec: 0.3728 Rec: 0.7051 F1: 0.4878\n",
      "2020-07-18 12:12:17,807 train loss in this epoch 0.482011\n",
      "2020-07-18 12:12:18,672 train loss in this epoch 0.480384\n",
      "2020-07-18 12:12:19,558 train loss in this epoch 0.483334\n",
      "2020-07-18 12:12:20,412 train loss in this epoch 0.482570\n",
      "2020-07-18 12:12:21,290 train loss in this epoch 0.483732\n",
      "2020-07-18 12:12:22,153 train loss in this epoch 0.483397\n",
      "2020-07-18 12:12:23,010 train loss in this epoch 0.483451\n",
      "2020-07-18 12:12:23,903 train loss in this epoch 0.484796\n",
      "2020-07-18 12:12:24,767 train loss in this epoch 0.484063\n",
      "2020-07-18 12:12:25,645 train loss in this epoch 0.482261\n",
      "2020-07-18 12:12:25,647 epoch 499, checkpoint!\n",
      "2020-07-18 12:13:33,190 valid_loss: 0.5092 AUC: 0.7156 Prec: 0.5581 Rec: 0.1456 F1: 0.2310\n",
      "2020-07-18 12:13:33,761 best threshold=-1.468486, f1=0.4892\n",
      "2020-07-18 12:13:42,900 using threshold -1.4685\n",
      "2020-07-18 12:13:43,263 test_loss: 0.5105 AUC: 0.7137 Prec: 0.3767 Rec: 0.6921 F1: 0.4879\n",
      "2020-07-18 12:13:43,268 optimization Finished!\n",
      "2020-07-18 12:13:43,270 total time elapsed: 4277.3928s\n",
      "2020-07-18 12:13:43,272 retrieve best threshold...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-17b42fa6a93c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"retrieve best threshold...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mbest_thr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_best_thr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_desc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t_total = time.time()\n",
    "logger.info(\"training...\")\n",
    "for epoch in range(500):\n",
    "    train(epoch, train_loader, valid_loader, test_loader)\n",
    "logger.info(\"optimization Finished!\")\n",
    "logger.info(\"total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "logger.info(\"retrieve best threshold...\")\n",
    "best_thr = evaluate(args.epochs, valid_loader, return_best_thr=True, log_desc='valid_')\n",
    "\n",
    "# Testing\n",
    "logger.info(\"testing...\")\n",
    "evaluate(500, test_loader, thr=best_thr, log_desc='test_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-18 12:19:23,076 valid_loss: 0.5092 AUC: 0.7156 Prec: 0.5581 Rec: 0.1456 F1: 0.2310\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in true_divide\n",
      "2020-07-18 12:19:23,652 best threshold=-1.468486, f1=0.4892\n",
      "2020-07-18 12:19:32,389 using threshold -1.4685\n",
      "2020-07-18 12:19:32,754 test_loss: 0.5105 AUC: 0.7137 Prec: 0.3767 Rec: 0.6921 F1: 0.4879\n"
     ]
    }
   ],
   "source": [
    "best_thr = evaluate(500, valid_loader, return_best_thr=True, log_desc='valid_')\n",
    "evaluate(500, test_loader, thr=best_thr, log_desc='test_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepInf_GAT ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 02:56:43,983 graphs loaded!\n",
      "2020-07-20 02:56:44,232 influence features loaded!\n",
      "2020-07-20 02:56:44,236 labels loaded!\n",
      "2020-07-20 02:56:44,349 vertex ids loaded!\n",
      "2020-07-20 02:56:45,070 global vertex features loaded!\n",
      "2020-07-20 02:58:04,401 64-dim embedding loaded!\n",
      "2020-07-20 02:58:04,404 779164 ego networks loaded, each with size 50\n"
     ]
    }
   ],
   "source": [
    "influence_dataset = InfluenceDataSet(\n",
    "            \"weibo/\", 64, 42, False, \"gat\")\n",
    "train_loader = DataLoader(influence_dataset, batch_size=1024,\n",
    "                        sampler=ChunkSampler(valid_start - train_start, 0))\n",
    "valid_loader = DataLoader(influence_dataset, batch_size=1024,\n",
    "                        sampler=ChunkSampler(test_start - valid_start, valid_start))\n",
    "test_loader = DataLoader(influence_dataset, batch_size=1024,\n",
    "                        sampler=ChunkSampler(N - test_start, test_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard_logger import *\n",
    "import shutil\n",
    "tensorboard_logger.clean_default_logger()\n",
    "logger = logging.getLogger(__name__)\n",
    "tensorboard_log_dir = 'log/%s' % ('gat')\n",
    "os.makedirs(tensorboard_log_dir, exist_ok=True)\n",
    "shutil.rmtree(tensorboard_log_dir)\n",
    "tensorboard_logger.configure(tensorboard_log_dir)\n",
    "logger.info('tensorboard logging to %s', tensorboard_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "global _default_logger\n",
    "_default_logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadGraphAttention(nn.Module):\n",
    "    def __init__(self, n_head, f_in, f_out, attn_dropout, bias=True):\n",
    "        super(MultiHeadGraphAttention, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.w = Parameter(torch.Tensor(n_head, f_in, f_out))\n",
    "        self.a_src = Parameter(torch.Tensor(n_head, f_out, 1))\n",
    "        self.a_dst = Parameter(torch.Tensor(n_head, f_out, 1))\n",
    "\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(f_out))\n",
    "            init.constant_(self.bias, 0)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        init.xavier_uniform_(self.w)\n",
    "        init.xavier_uniform_(self.a_src)\n",
    "        init.xavier_uniform_(self.a_dst)\n",
    "\n",
    "    def forward(self, h, adj):\n",
    "        n = h.size(0) # h is of size n x f_in\n",
    "        h_prime = torch.matmul(h.unsqueeze(0), self.w) #  n_head x n x f_out\n",
    "        attn_src = torch.bmm(h_prime, self.a_src) # n_head x n x 1\n",
    "        attn_dst = torch.bmm(h_prime, self.a_dst) # n_head x n x 1\n",
    "        attn = attn_src.expand(-1, -1, n) + attn_dst.expand(-1, -1, n).permute(0, 2, 1) # n_head x n x n\n",
    "\n",
    "        attn = self.leaky_relu(attn)\n",
    "        attn.data.masked_fill_(1 - adj, float(\"-inf\"))\n",
    "        attn = self.softmax(attn) # n_head x n x n\n",
    "        attn = self.dropout(attn)\n",
    "        output = torch.bmm(attn, h_prime) # n_head x n x f_out\n",
    "\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "\n",
    "class BatchMultiHeadGraphAttention(nn.Module):\n",
    "    def __init__(self, n_head, f_in, f_out, attn_dropout, bias=True):\n",
    "        super(BatchMultiHeadGraphAttention, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.w = Parameter(torch.Tensor(n_head, f_in, f_out))\n",
    "        self.a_src = Parameter(torch.Tensor(n_head, f_out, 1))\n",
    "        self.a_dst = Parameter(torch.Tensor(n_head, f_out, 1))\n",
    "\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(f_out))\n",
    "            init.constant_(self.bias, 0)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        init.xavier_uniform_(self.w)\n",
    "        init.xavier_uniform_(self.a_src)\n",
    "        init.xavier_uniform_(self.a_dst)\n",
    "\n",
    "    def forward(self, h, adj):\n",
    "        bs, n = h.shape[:2] # h is of size bs x n x f_in\n",
    "        h_prime = torch.matmul(h.unsqueeze(1), self.w) # bs x n_head x n x f_out\n",
    "        attn_src = torch.matmul(F.tanh(h_prime), self.a_src) # bs x n_head x n x 1\n",
    "        attn_dst = torch.matmul(F.tanh(h_prime), self.a_dst) # bs x n_head x n x 1\n",
    "        attn = attn_src.expand(-1, -1, -1, n) + attn_dst.expand(-1, -1, -1, n).permute(0, 1, 3, 2) # bs x n_head x n x n\n",
    "\n",
    "        attn = self.leaky_relu(attn)\n",
    "        mask = 1 - adj.unsqueeze(1) # bs x 1 x n x n\n",
    "        attn.data.masked_fill_(mask, float(\"-inf\"))\n",
    "        attn = self.softmax(attn) # bs x n_head x n x n\n",
    "        attn = self.dropout(attn)\n",
    "        output = torch.matmul(attn, h_prime) # bs x n_head x n x f_out\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGAT(nn.Module):\n",
    "    def __init__(self, pretrained_emb, vertex_feature, use_vertex_feature,\n",
    "            n_units=[1433, 8, 7], n_heads=[8, 1],\n",
    "            dropout=0.1, attn_dropout=0.0, fine_tune=False,\n",
    "            instance_normalization=False):\n",
    "        super(BatchGAT, self).__init__()\n",
    "        self.n_layer = len(n_units) - 1\n",
    "        self.dropout = dropout\n",
    "        self.inst_norm = instance_normalization\n",
    "        if self.inst_norm:\n",
    "            self.norm = nn.InstanceNorm1d(pretrained_emb.size(1), momentum=0.0, affine=True)\n",
    "\n",
    "        # https://discuss.pytorch.org/t/can-we-use-pre-trained-word-embeddings-for-weight-initialization-in-nn-embedding/1222/2\n",
    "        self.embedding = nn.Embedding(pretrained_emb.size(0), pretrained_emb.size(1))\n",
    "        self.embedding.weight = nn.Parameter(pretrained_emb)\n",
    "        self.embedding.weight.requires_grad = fine_tune\n",
    "        n_units[0] += pretrained_emb.size(1)\n",
    "\n",
    "        self.use_vertex_feature = use_vertex_feature\n",
    "        if self.use_vertex_feature:\n",
    "            self.vertex_feature = nn.Embedding(vertex_feature.size(0), vertex_feature.size(1))\n",
    "            self.vertex_feature.weight = nn.Parameter(vertex_feature)\n",
    "            self.vertex_feature.weight.requires_grad = False\n",
    "            n_units[0] += vertex_feature.size(1)\n",
    "\n",
    "        self.layer_stack = nn.ModuleList()\n",
    "        for i in range(self.n_layer):\n",
    "            # consider multi head from last layer\n",
    "            f_in = n_units[i] * n_heads[i - 1] if i else n_units[i]\n",
    "            self.layer_stack.append(\n",
    "                    BatchMultiHeadGraphAttention(n_heads[i], f_in=f_in,\n",
    "                        f_out=n_units[i + 1], attn_dropout=attn_dropout)\n",
    "                    )\n",
    "\n",
    "    def forward(self, x, vertices, adj):\n",
    "        emb = self.embedding(vertices)\n",
    "        if self.inst_norm:\n",
    "            emb = self.norm(emb.transpose(1, 2)).transpose(1, 2)\n",
    "        x = torch.cat((x, emb), dim=2)\n",
    "        if self.use_vertex_feature:\n",
    "            vfeature = self.vertex_feature(vertices)\n",
    "            x = torch.cat((x, vfeature), dim=2)\n",
    "        bs, n = adj.size()[:2]\n",
    "        for i, gat_layer in enumerate(self.layer_stack):\n",
    "            x = gat_layer(x, adj) # bs x n_head x n x f_out\n",
    "            if i + 1 == self.n_layer:\n",
    "                x = x.mean(dim=1)\n",
    "            else:\n",
    "                x = F.elu(x.transpose(1, 2).contiguous().view(bs, n, -1))\n",
    "                x = F.dropout(x, self.dropout, training=self.training)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_heads = [int(x) for x in [8,8,1]]\n",
    "hidden_units = \"16,16\"\n",
    "feature_dim = influence_dataset.get_feature_dimension()\n",
    "n_units = [feature_dim] + [int(x) for x in hidden_units.strip().split(\",\")] + [n_classes]\n",
    "model = BatchGAT(pretrained_emb=influence_dataset.get_embedding(),\n",
    "            vertex_feature=influence_dataset.get_vertex_features(),\n",
    "            use_vertex_feature= False,\n",
    "            n_units=n_units, n_heads=n_heads,\n",
    "            dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 03:10:19,245 training...\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]2020-07-20 03:10:25,244 train loss in this epoch 0.696429\n",
      "  0%|          | 1/500 [00:05<49:52,  6.00s/it]2020-07-20 03:10:31,043 train loss in this epoch 0.696432\n",
      "  0%|          | 2/500 [00:11<49:16,  5.94s/it]2020-07-20 03:10:36,963 train loss in this epoch 0.696405\n",
      "  1%|          | 3/500 [00:17<49:08,  5.93s/it]2020-07-20 03:10:42,815 train loss in this epoch 0.696425\n",
      "  1%|          | 4/500 [00:23<48:50,  5.91s/it]2020-07-20 03:10:48,732 train loss in this epoch 0.696376\n",
      "  1%|          | 5/500 [00:29<48:46,  5.91s/it]2020-07-20 03:10:54,738 train loss in this epoch 0.696377\n",
      "  1%|          | 6/500 [00:35<48:53,  5.94s/it]2020-07-20 03:11:00,451 train loss in this epoch 0.696474\n",
      "  1%|▏         | 7/500 [00:41<48:14,  5.87s/it]2020-07-20 03:11:06,309 train loss in this epoch 0.696454\n",
      "  2%|▏         | 8/500 [00:47<48:06,  5.87s/it]2020-07-20 03:11:12,276 train loss in this epoch 0.696396\n",
      "  2%|▏         | 9/500 [00:53<48:15,  5.90s/it]2020-07-20 03:11:18,217 train loss in this epoch 0.696413\n",
      "2020-07-20 03:11:18,219 epoch 9, checkpoint!\n",
      "2020-07-20 03:16:44,667 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 03:16:45,227 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 03:17:31,334 using threshold -0.7295\n",
      "2020-07-20 03:17:31,576 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      "  2%|▏         | 10/500 [07:12<16:02:59, 117.92s/it]2020-07-20 03:17:37,115 train loss in this epoch 0.696379\n",
      "  2%|▏         | 11/500 [07:17<11:26:15, 84.20s/it] 2020-07-20 03:17:43,103 train loss in this epoch 0.696430\n",
      "  2%|▏         | 12/500 [07:23<8:14:00, 60.74s/it] 2020-07-20 03:17:48,758 train loss in this epoch 0.696458\n",
      "  3%|▎         | 13/500 [07:29<5:58:52, 44.21s/it]2020-07-20 03:17:54,720 train loss in this epoch 0.696442\n",
      "  3%|▎         | 14/500 [07:35<4:25:11, 32.74s/it]2020-07-20 03:18:00,649 train loss in this epoch 0.696385\n",
      "  3%|▎         | 15/500 [07:41<3:19:37, 24.70s/it]2020-07-20 03:18:06,413 train loss in this epoch 0.696377\n",
      "  3%|▎         | 16/500 [07:47<2:33:23, 19.02s/it]2020-07-20 03:18:12,082 train loss in this epoch 0.696385\n",
      "  3%|▎         | 17/500 [07:52<2:00:50, 15.01s/it]2020-07-20 03:18:17,635 train loss in this epoch 0.696507\n",
      "  4%|▎         | 18/500 [07:58<1:37:48, 12.17s/it]2020-07-20 03:18:23,663 train loss in this epoch 0.696410\n",
      "  4%|▍         | 19/500 [08:04<1:22:48, 10.33s/it]2020-07-20 03:18:29,746 train loss in this epoch 0.696338\n",
      "2020-07-20 03:18:29,748 epoch 19, checkpoint!\n",
      "2020-07-20 03:23:55,137 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 03:23:55,695 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 03:24:41,511 using threshold -0.7295\n",
      "2020-07-20 03:24:41,751 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      "  4%|▍         | 20/500 [14:22<16:05:15, 120.66s/it]2020-07-20 03:24:47,597 train loss in this epoch 0.696406\n",
      "  4%|▍         | 21/500 [14:28<11:28:16, 86.21s/it] 2020-07-20 03:24:53,299 train loss in this epoch 0.696389\n",
      "  4%|▍         | 22/500 [14:34<8:14:24, 62.06s/it] 2020-07-20 03:24:59,214 train loss in this epoch 0.696411\n",
      "  5%|▍         | 23/500 [14:39<5:59:28, 45.22s/it]2020-07-20 03:25:05,223 train loss in this epoch 0.696426\n",
      "  5%|▍         | 24/500 [14:45<4:25:24, 33.45s/it]2020-07-20 03:25:10,973 train loss in this epoch 0.696396\n",
      "  5%|▌         | 25/500 [14:51<3:19:02, 25.14s/it]2020-07-20 03:25:16,918 train loss in this epoch 0.696486\n",
      "  5%|▌         | 26/500 [14:57<2:33:07, 19.38s/it]2020-07-20 03:25:23,097 train loss in this epoch 0.696500\n",
      "  5%|▌         | 27/500 [15:03<2:01:34, 15.42s/it]2020-07-20 03:25:29,062 train loss in this epoch 0.696442\n",
      "  6%|▌         | 28/500 [15:09<1:39:00, 12.58s/it]2020-07-20 03:25:34,580 train loss in this epoch 0.696498\n",
      "  6%|▌         | 29/500 [15:15<1:22:09, 10.47s/it]2020-07-20 03:25:40,277 train loss in this epoch 0.696432\n",
      "2020-07-20 03:25:40,279 epoch 29, checkpoint!\n",
      "2020-07-20 03:30:51,959 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 03:30:52,517 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 03:31:37,349 using threshold -0.7295\n",
      "2020-07-20 03:31:37,634 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      "  6%|▌         | 30/500 [21:18<15:10:33, 116.24s/it]2020-07-20 03:31:43,563 train loss in this epoch 0.696400\n",
      "  6%|▌         | 31/500 [21:24<10:49:56, 83.15s/it] 2020-07-20 03:31:49,157 train loss in this epoch 0.696384\n",
      "  6%|▋         | 32/500 [21:29<7:47:04, 59.88s/it] 2020-07-20 03:31:54,954 train loss in this epoch 0.696431\n",
      "  7%|▋         | 33/500 [21:35<5:39:47, 43.66s/it]2020-07-20 03:32:00,690 train loss in this epoch 0.696406\n",
      "  7%|▋         | 34/500 [21:41<4:10:42, 32.28s/it]2020-07-20 03:32:06,598 train loss in this epoch 0.696391\n",
      "  7%|▋         | 35/500 [21:47<3:08:51, 24.37s/it]2020-07-20 03:32:12,161 train loss in this epoch 0.696397\n",
      "  7%|▋         | 36/500 [21:52<2:24:49, 18.73s/it]2020-07-20 03:32:18,206 train loss in this epoch 0.696428\n",
      "  7%|▋         | 37/500 [21:58<1:55:09, 14.92s/it]2020-07-20 03:32:24,246 train loss in this epoch 0.696377\n",
      "  8%|▊         | 38/500 [22:04<1:34:23, 12.26s/it]2020-07-20 03:32:29,859 train loss in this epoch 0.696482\n",
      "  8%|▊         | 39/500 [22:10<1:18:51, 10.26s/it]2020-07-20 03:32:35,576 train loss in this epoch 0.696386\n",
      "2020-07-20 03:32:35,578 epoch 39, checkpoint!\n",
      "2020-07-20 03:37:50,470 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 03:37:51,030 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 03:38:36,128 using threshold -0.7295\n",
      "2020-07-20 03:38:36,369 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      "  8%|▊         | 40/500 [28:17<14:58:03, 117.14s/it]2020-07-20 03:38:42,170 train loss in this epoch 0.696441\n",
      "  8%|▊         | 41/500 [28:22<10:40:35, 83.74s/it] 2020-07-20 03:38:47,837 train loss in this epoch 0.696494\n",
      "  8%|▊         | 42/500 [28:28<7:40:24, 60.32s/it] 2020-07-20 03:38:53,467 train loss in this epoch 0.696391\n",
      "  9%|▊         | 43/500 [28:34<5:34:26, 43.91s/it]2020-07-20 03:38:59,091 train loss in this epoch 0.696442\n",
      "  9%|▉         | 44/500 [28:39<4:06:25, 32.42s/it]2020-07-20 03:39:04,559 train loss in this epoch 0.696409\n",
      "  9%|▉         | 45/500 [28:45<3:04:33, 24.34s/it]2020-07-20 03:39:10,080 train loss in this epoch 0.696467\n",
      "  9%|▉         | 46/500 [28:50<2:21:26, 18.69s/it]2020-07-20 03:39:15,680 train loss in this epoch 0.696432\n",
      "  9%|▉         | 47/500 [28:56<1:51:28, 14.76s/it]2020-07-20 03:39:21,672 train loss in this epoch 0.696452\n",
      " 10%|▉         | 48/500 [29:02<1:31:24, 12.13s/it]2020-07-20 03:39:27,477 train loss in this epoch 0.696394\n",
      " 10%|▉         | 49/500 [29:08<1:16:55, 10.23s/it]2020-07-20 03:39:33,006 train loss in this epoch 0.696495\n",
      "2020-07-20 03:39:33,008 epoch 49, checkpoint!\n",
      "2020-07-20 03:44:51,574 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 03:44:52,133 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 03:45:36,971 using threshold -0.7295\n",
      "2020-07-20 03:45:37,211 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 10%|█         | 50/500 [35:17<14:45:37, 118.08s/it]2020-07-20 03:45:42,517 train loss in this epoch 0.696387\n",
      " 10%|█         | 51/500 [35:23<10:30:28, 84.25s/it] 2020-07-20 03:45:48,062 train loss in this epoch 0.696397\n",
      " 10%|█         | 52/500 [35:28<7:32:46, 60.64s/it] 2020-07-20 03:45:53,703 train loss in this epoch 0.696417\n",
      " 11%|█         | 53/500 [35:34<5:28:50, 44.14s/it]2020-07-20 03:45:59,522 train loss in this epoch 0.696438\n",
      " 11%|█         | 54/500 [35:40<4:02:38, 32.64s/it]2020-07-20 03:46:04,994 train loss in this epoch 0.696444\n",
      " 11%|█         | 55/500 [35:45<3:01:39, 24.49s/it]2020-07-20 03:46:10,692 train loss in this epoch 0.696339\n",
      " 11%|█         | 56/500 [35:51<2:19:31, 18.85s/it]2020-07-20 03:46:16,559 train loss in this epoch 0.696402\n",
      " 11%|█▏        | 57/500 [35:57<1:50:26, 14.96s/it]2020-07-20 03:46:22,441 train loss in this epoch 0.696447\n",
      " 12%|█▏        | 58/500 [36:03<1:30:07, 12.23s/it]2020-07-20 03:46:28,079 train loss in this epoch 0.696416\n",
      " 12%|█▏        | 59/500 [36:08<1:15:22, 10.26s/it]2020-07-20 03:46:34,127 train loss in this epoch 0.696409\n",
      "2020-07-20 03:46:34,128 epoch 59, checkpoint!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 03:51:45,807 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 03:51:46,367 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 03:52:30,863 using threshold -0.7295\n",
      "2020-07-20 03:52:31,336 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 12%|█▏        | 60/500 [42:12<14:11:49, 116.16s/it]2020-07-20 03:52:37,062 train loss in this epoch 0.696385\n",
      " 12%|█▏        | 61/500 [42:17<10:07:29, 83.03s/it] 2020-07-20 03:52:43,066 train loss in this epoch 0.696388\n",
      " 12%|█▏        | 62/500 [42:23<7:17:24, 59.92s/it] 2020-07-20 03:52:48,990 train loss in this epoch 0.696431\n",
      " 13%|█▎        | 63/500 [42:29<5:18:26, 43.72s/it]2020-07-20 03:52:54,491 train loss in this epoch 0.696376\n",
      " 13%|█▎        | 64/500 [42:35<3:54:23, 32.26s/it]2020-07-20 03:53:00,227 train loss in this epoch 0.696377\n",
      " 13%|█▎        | 65/500 [42:40<2:56:10, 24.30s/it]2020-07-20 03:53:05,999 train loss in this epoch 0.696456\n",
      " 13%|█▎        | 66/500 [42:46<2:15:33, 18.74s/it]2020-07-20 03:53:11,491 train loss in this epoch 0.696458\n",
      " 13%|█▎        | 67/500 [42:52<1:46:33, 14.77s/it]2020-07-20 03:53:17,164 train loss in this epoch 0.696376\n",
      " 14%|█▎        | 68/500 [42:57<1:26:40, 12.04s/it]2020-07-20 03:53:23,164 train loss in this epoch 0.696386\n",
      " 14%|█▍        | 69/500 [43:03<1:13:27, 10.23s/it]2020-07-20 03:53:29,004 train loss in this epoch 0.696448\n",
      "2020-07-20 03:53:29,006 epoch 69, checkpoint!\n",
      "2020-07-20 03:58:42,806 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 03:58:43,364 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 03:59:27,979 using threshold -0.7295\n",
      "2020-07-20 03:59:28,433 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 14%|█▍        | 70/500 [49:09<13:56:37, 116.74s/it]2020-07-20 03:59:34,052 train loss in this epoch 0.696395\n",
      " 14%|█▍        | 71/500 [49:14<9:56:20, 83.40s/it]  2020-07-20 03:59:39,654 train loss in this epoch 0.696455\n",
      " 14%|█▍        | 72/500 [49:20<7:08:26, 60.06s/it]2020-07-20 03:59:45,575 train loss in this epoch 0.696388\n",
      " 15%|█▍        | 73/500 [49:26<5:11:51, 43.82s/it]2020-07-20 03:59:51,148 train loss in this epoch 0.696413\n",
      " 15%|█▍        | 74/500 [49:31<3:49:39, 32.35s/it]2020-07-20 03:59:57,027 train loss in this epoch 0.696437\n",
      " 15%|█▌        | 75/500 [49:37<2:52:52, 24.41s/it]2020-07-20 04:00:02,762 train loss in this epoch 0.696412\n",
      " 15%|█▌        | 76/500 [49:43<2:12:53, 18.80s/it]2020-07-20 04:00:08,590 train loss in this epoch 0.696398\n",
      " 15%|█▌        | 77/500 [49:49<1:45:07, 14.91s/it]2020-07-20 04:00:14,448 train loss in this epoch 0.696427\n",
      " 16%|█▌        | 78/500 [49:55<1:25:46, 12.20s/it]2020-07-20 04:00:20,103 train loss in this epoch 0.696432\n",
      " 16%|█▌        | 79/500 [50:00<1:11:48, 10.23s/it]2020-07-20 04:00:25,804 train loss in this epoch 0.696372\n",
      "2020-07-20 04:00:25,806 epoch 79, checkpoint!\n",
      "2020-07-20 04:05:44,214 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 04:05:44,773 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 04:06:29,664 using threshold -0.7295\n",
      "2020-07-20 04:06:29,992 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 16%|█▌        | 80/500 [56:10<13:46:54, 118.13s/it]2020-07-20 04:06:35,535 train loss in this epoch 0.696315\n",
      " 16%|█▌        | 81/500 [56:16<9:49:04, 84.35s/it]  2020-07-20 04:06:41,516 train loss in this epoch 0.696359\n",
      " 16%|█▋        | 82/500 [56:22<7:03:52, 60.84s/it]2020-07-20 04:06:47,517 train loss in this epoch 0.696382\n",
      " 17%|█▋        | 83/500 [56:28<5:08:30, 44.39s/it]2020-07-20 04:06:53,043 train loss in this epoch 0.696471\n",
      " 17%|█▋        | 84/500 [56:33<3:46:55, 32.73s/it]2020-07-20 04:06:59,027 train loss in this epoch 0.696449\n",
      " 17%|█▋        | 85/500 [56:39<2:50:53, 24.71s/it]2020-07-20 04:07:05,139 train loss in this epoch 0.696390\n",
      " 17%|█▋        | 86/500 [56:45<2:11:59, 19.13s/it]2020-07-20 04:07:10,818 train loss in this epoch 0.696368\n",
      " 17%|█▋        | 87/500 [56:51<1:43:53, 15.09s/it]2020-07-20 04:07:16,532 train loss in this epoch 0.696414\n",
      " 18%|█▊        | 88/500 [56:57<1:24:19, 12.28s/it]2020-07-20 04:07:22,301 train loss in this epoch 0.696376\n",
      " 18%|█▊        | 89/500 [57:03<1:10:44, 10.33s/it]2020-07-20 04:07:28,104 train loss in this epoch 0.696387\n",
      "2020-07-20 04:07:28,107 epoch 89, checkpoint!\n",
      "2020-07-20 04:12:42,039 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 04:12:42,597 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 04:13:27,639 using threshold -0.7295\n",
      "2020-07-20 04:13:27,955 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 18%|█▊        | 90/500 [1:03:08<13:18:59, 116.93s/it]2020-07-20 04:13:34,277 train loss in this epoch 0.696440\n",
      " 18%|█▊        | 91/500 [1:03:15<9:30:51, 83.74s/it]  2020-07-20 04:13:40,107 train loss in this epoch 0.696433\n",
      " 18%|█▊        | 92/500 [1:03:20<6:50:30, 60.37s/it]2020-07-20 04:13:46,157 train loss in this epoch 0.696352\n",
      " 19%|█▊        | 93/500 [1:03:26<4:58:58, 44.07s/it]2020-07-20 04:13:52,037 train loss in this epoch 0.696415\n",
      " 19%|█▉        | 94/500 [1:03:32<3:40:41, 32.62s/it]2020-07-20 04:13:57,993 train loss in this epoch 0.696444\n",
      " 19%|█▉        | 95/500 [1:03:38<2:46:10, 24.62s/it]2020-07-20 04:14:03,565 train loss in this epoch 0.696431\n",
      " 19%|█▉        | 96/500 [1:03:44<2:07:17, 18.90s/it]2020-07-20 04:14:09,414 train loss in this epoch 0.696418\n",
      " 19%|█▉        | 97/500 [1:03:50<1:40:39, 14.99s/it]2020-07-20 04:14:15,003 train loss in this epoch 0.696404\n",
      " 20%|█▉        | 98/500 [1:03:55<1:21:31, 12.17s/it]2020-07-20 04:14:20,838 train loss in this epoch 0.696388\n",
      " 20%|█▉        | 99/500 [1:04:01<1:08:37, 10.27s/it]2020-07-20 04:14:26,506 train loss in this epoch 0.696440\n",
      "2020-07-20 04:14:26,508 epoch 99, checkpoint!\n",
      "2020-07-20 04:19:43,376 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 04:19:43,937 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 04:20:29,595 using threshold -0.7295\n",
      "2020-07-20 04:20:29,842 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 20%|██        | 100/500 [1:10:10<13:05:55, 117.89s/it]2020-07-20 04:20:35,606 train loss in this epoch 0.696475\n",
      " 20%|██        | 101/500 [1:10:16<9:20:16, 84.25s/it]  2020-07-20 04:20:41,117 train loss in this epoch 0.696401\n",
      " 20%|██        | 102/500 [1:10:21<6:42:10, 60.63s/it]2020-07-20 04:20:47,032 train loss in this epoch 0.696348\n",
      " 21%|██        | 103/500 [1:10:27<4:52:33, 44.21s/it]2020-07-20 04:20:52,919 train loss in this epoch 0.696461\n",
      " 21%|██        | 104/500 [1:10:33<3:35:55, 32.72s/it]2020-07-20 04:20:58,513 train loss in this epoch 0.696427\n",
      " 21%|██        | 105/500 [1:10:39<2:41:48, 24.58s/it]2020-07-20 04:21:04,074 train loss in this epoch 0.696365\n",
      " 21%|██        | 106/500 [1:10:44<2:03:56, 18.87s/it]2020-07-20 04:21:10,043 train loss in this epoch 0.696410\n",
      " 21%|██▏       | 107/500 [1:10:50<1:38:16, 15.00s/it]2020-07-20 04:21:15,870 train loss in this epoch 0.696407\n",
      " 22%|██▏       | 108/500 [1:10:56<1:20:01, 12.25s/it]2020-07-20 04:21:21,758 train loss in this epoch 0.696515\n",
      " 22%|██▏       | 109/500 [1:11:02<1:07:23, 10.34s/it]2020-07-20 04:21:27,452 train loss in this epoch 0.696393\n",
      "2020-07-20 04:21:27,454 epoch 109, checkpoint!\n",
      "2020-07-20 04:26:40,967 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 04:26:41,526 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 04:27:25,370 using threshold -0.7295\n",
      "2020-07-20 04:27:25,611 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 22%|██▏       | 110/500 [1:17:06<12:36:33, 116.39s/it]2020-07-20 04:27:31,566 train loss in this epoch 0.696367\n",
      " 22%|██▏       | 111/500 [1:17:12<8:59:49, 83.26s/it]  2020-07-20 04:27:37,517 train loss in this epoch 0.696483\n",
      " 22%|██▏       | 112/500 [1:17:18<6:28:26, 60.07s/it]2020-07-20 04:27:43,350 train loss in this epoch 0.696345\n",
      " 23%|██▎       | 113/500 [1:17:24<4:42:30, 43.80s/it]2020-07-20 04:27:49,112 train loss in this epoch 0.696437\n",
      " 23%|██▎       | 114/500 [1:17:29<3:28:21, 32.39s/it]2020-07-20 04:27:55,006 train loss in this epoch 0.696410\n",
      " 23%|██▎       | 115/500 [1:17:35<2:36:49, 24.44s/it]2020-07-20 04:28:01,095 train loss in this epoch 0.696423\n",
      " 23%|██▎       | 116/500 [1:17:41<2:01:10, 18.93s/it]2020-07-20 04:28:06,694 train loss in this epoch 0.696453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 117/500 [1:17:47<1:35:19, 14.93s/it]2020-07-20 04:28:12,594 train loss in this epoch 0.696388\n",
      " 24%|██▎       | 118/500 [1:17:53<1:17:49, 12.22s/it]2020-07-20 04:28:18,318 train loss in this epoch 0.696325\n",
      " 24%|██▍       | 119/500 [1:17:59<1:05:14, 10.27s/it]2020-07-20 04:28:23,971 train loss in this epoch 0.696380\n",
      "2020-07-20 04:28:23,973 epoch 119, checkpoint!\n",
      "2020-07-20 04:33:38,351 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 04:33:38,910 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 04:34:22,859 using threshold -0.7295\n",
      "2020-07-20 04:34:23,100 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 24%|██▍       | 120/500 [1:24:03<12:18:37, 116.63s/it]2020-07-20 04:34:28,793 train loss in this epoch 0.696356\n",
      " 24%|██▍       | 121/500 [1:24:09<8:46:28, 83.35s/it]  2020-07-20 04:34:34,706 train loss in this epoch 0.696466\n",
      " 24%|██▍       | 122/500 [1:24:15<6:18:44, 60.12s/it]2020-07-20 04:34:40,796 train loss in this epoch 0.696449\n",
      " 25%|██▍       | 123/500 [1:24:21<4:35:53, 43.91s/it]2020-07-20 04:34:46,491 train loss in this epoch 0.696491\n",
      " 25%|██▍       | 124/500 [1:24:27<3:23:19, 32.44s/it]2020-07-20 04:34:52,577 train loss in this epoch 0.696452\n",
      " 25%|██▌       | 125/500 [1:24:33<2:33:21, 24.54s/it]2020-07-20 04:34:58,480 train loss in this epoch 0.696381\n",
      " 25%|██▌       | 126/500 [1:24:39<1:58:05, 18.95s/it]2020-07-20 04:35:04,202 train loss in this epoch 0.696413\n",
      " 25%|██▌       | 127/500 [1:24:44<1:33:07, 14.98s/it]2020-07-20 04:35:09,986 train loss in this epoch 0.696380\n",
      " 26%|██▌       | 128/500 [1:24:50<1:15:46, 12.22s/it]2020-07-20 04:35:15,545 train loss in this epoch 0.696426\n",
      " 26%|██▌       | 129/500 [1:24:56<1:03:12, 10.22s/it]2020-07-20 04:35:21,397 train loss in this epoch 0.696419\n",
      "2020-07-20 04:35:21,399 epoch 129, checkpoint!\n",
      "2020-07-20 04:40:30,662 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 04:40:31,220 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 04:41:16,821 using threshold -0.7295\n",
      "2020-07-20 04:41:17,063 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 26%|██▌       | 130/500 [1:30:57<11:52:56, 115.61s/it]2020-07-20 04:41:22,406 train loss in this epoch 0.696428\n",
      " 26%|██▌       | 131/500 [1:31:03<8:27:33, 82.53s/it]  2020-07-20 04:41:28,110 train loss in this epoch 0.696445\n",
      " 26%|██▋       | 132/500 [1:31:08<6:04:49, 59.48s/it]2020-07-20 04:41:34,132 train loss in this epoch 0.696449\n",
      " 27%|██▋       | 133/500 [1:31:14<4:25:44, 43.44s/it]2020-07-20 04:41:39,961 train loss in this epoch 0.696502\n",
      " 27%|██▋       | 134/500 [1:31:20<3:16:10, 32.16s/it]2020-07-20 04:41:45,676 train loss in this epoch 0.696400\n",
      " 27%|██▋       | 135/500 [1:31:26<2:27:22, 24.23s/it]2020-07-20 04:41:51,639 train loss in this epoch 0.696447\n",
      " 27%|██▋       | 136/500 [1:31:32<1:53:44, 18.75s/it]2020-07-20 04:41:57,500 train loss in this epoch 0.696495\n",
      " 27%|██▋       | 137/500 [1:31:38<1:30:01, 14.88s/it]2020-07-20 04:42:03,437 train loss in this epoch 0.696484\n",
      " 28%|██▊       | 138/500 [1:31:44<1:13:35, 12.20s/it]2020-07-20 04:42:09,142 train loss in this epoch 0.696471\n",
      " 28%|██▊       | 139/500 [1:31:49<1:01:40, 10.25s/it]2020-07-20 04:42:15,104 train loss in this epoch 0.696427\n",
      "2020-07-20 04:42:15,106 epoch 139, checkpoint!\n",
      "2020-07-20 04:47:32,462 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 04:47:33,020 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 04:48:17,150 using threshold -0.7295\n",
      "2020-07-20 04:48:17,394 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 28%|██▊       | 140/500 [1:37:58<11:45:54, 117.65s/it]2020-07-20 04:48:22,961 train loss in this epoch 0.696410\n",
      " 28%|██▊       | 141/500 [1:38:03<8:22:45, 84.03s/it]  2020-07-20 04:48:29,041 train loss in this epoch 0.696390\n",
      " 28%|██▊       | 142/500 [1:38:09<6:01:49, 60.64s/it]2020-07-20 04:48:34,931 train loss in this epoch 0.696401\n",
      " 29%|██▊       | 143/500 [1:38:15<4:23:05, 44.22s/it]2020-07-20 04:48:40,817 train loss in this epoch 0.696340\n",
      " 29%|██▉       | 144/500 [1:38:21<3:14:07, 32.72s/it]2020-07-20 04:48:46,449 train loss in this epoch 0.696394\n",
      " 29%|██▉       | 145/500 [1:38:27<2:25:30, 24.59s/it]2020-07-20 04:48:52,569 train loss in this epoch 0.696428\n",
      " 29%|██▉       | 146/500 [1:38:33<1:52:23, 19.05s/it]2020-07-20 04:48:58,427 train loss in this epoch 0.696449\n",
      " 29%|██▉       | 147/500 [1:38:39<1:28:47, 15.09s/it]2020-07-20 04:49:04,114 train loss in this epoch 0.696327\n",
      " 30%|██▉       | 148/500 [1:38:44<1:11:59, 12.27s/it]2020-07-20 04:49:09,929 train loss in this epoch 0.696409\n",
      " 30%|██▉       | 149/500 [1:38:50<1:00:27, 10.33s/it]2020-07-20 04:49:15,643 train loss in this epoch 0.696446\n",
      "2020-07-20 04:49:15,646 epoch 149, checkpoint!\n",
      "2020-07-20 04:54:30,280 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 04:54:30,839 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 04:55:15,821 using threshold -0.7295\n",
      "2020-07-20 04:55:16,063 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 30%|███       | 150/500 [1:44:56<11:22:55, 117.07s/it]2020-07-20 04:55:21,915 train loss in this epoch 0.696419\n",
      " 30%|███       | 151/500 [1:45:02<8:06:53, 83.71s/it]  2020-07-20 04:55:27,931 train loss in this epoch 0.696426\n",
      " 30%|███       | 152/500 [1:45:08<5:50:19, 60.40s/it]2020-07-20 04:55:33,596 train loss in this epoch 0.696459\n",
      " 31%|███       | 153/500 [1:45:14<4:14:20, 43.98s/it]2020-07-20 04:55:39,533 train loss in this epoch 0.696408\n",
      " 31%|███       | 154/500 [1:45:20<3:07:48, 32.57s/it]2020-07-20 04:55:45,355 train loss in this epoch 0.696378\n",
      " 31%|███       | 155/500 [1:45:26<2:21:07, 24.54s/it]2020-07-20 04:55:50,956 train loss in this epoch 0.696375\n",
      " 31%|███       | 156/500 [1:45:31<1:48:08, 18.86s/it]2020-07-20 04:55:56,578 train loss in this epoch 0.696390\n",
      " 31%|███▏      | 157/500 [1:45:37<1:25:06, 14.89s/it]2020-07-20 04:56:02,511 train loss in this epoch 0.696424\n",
      " 32%|███▏      | 158/500 [1:45:43<1:09:33, 12.20s/it]2020-07-20 04:56:08,401 train loss in this epoch 0.696389\n",
      " 32%|███▏      | 159/500 [1:45:49<58:35, 10.31s/it]  2020-07-20 04:56:14,221 train loss in this epoch 0.696439\n",
      "2020-07-20 04:56:14,223 epoch 159, checkpoint!\n",
      "2020-07-20 05:01:28,331 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 05:01:28,890 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 05:02:14,115 using threshold -0.7295\n",
      "2020-07-20 05:02:14,544 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 32%|███▏      | 160/500 [1:51:55<11:03:20, 117.06s/it]2020-07-20 05:02:20,529 train loss in this epoch 0.696431\n",
      " 32%|███▏      | 161/500 [1:52:01<7:53:06, 83.74s/it]  2020-07-20 05:02:26,406 train loss in this epoch 0.696411\n",
      " 32%|███▏      | 162/500 [1:52:07<5:40:08, 60.38s/it]2020-07-20 05:02:32,106 train loss in this epoch 0.696412\n",
      " 33%|███▎      | 163/500 [1:52:12<4:06:59, 43.98s/it]2020-07-20 05:02:38,208 train loss in this epoch 0.696448\n",
      " 33%|███▎      | 164/500 [1:52:18<3:02:37, 32.61s/it]2020-07-20 05:02:43,855 train loss in this epoch 0.696405\n",
      " 33%|███▎      | 165/500 [1:52:24<2:16:55, 24.52s/it]2020-07-20 05:02:49,444 train loss in this epoch 0.696388\n",
      " 33%|███▎      | 166/500 [1:52:30<1:44:53, 18.84s/it]2020-07-20 05:02:55,005 train loss in this epoch 0.696364\n",
      " 33%|███▎      | 167/500 [1:52:35<1:22:27, 14.86s/it]2020-07-20 05:03:00,883 train loss in this epoch 0.696501\n",
      " 34%|███▎      | 168/500 [1:52:41<1:07:18, 12.16s/it]2020-07-20 05:03:06,425 train loss in this epoch 0.696375\n",
      " 34%|███▍      | 169/500 [1:52:47<56:08, 10.18s/it]  2020-07-20 05:03:12,362 train loss in this epoch 0.696418\n",
      "2020-07-20 05:03:12,365 epoch 169, checkpoint!\n",
      "2020-07-20 05:08:26,254 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 05:08:26,816 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 05:09:11,996 using threshold -0.7295\n",
      "2020-07-20 05:09:12,237 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 34%|███▍      | 170/500 [1:58:52<10:42:46, 116.87s/it]2020-07-20 05:09:17,947 train loss in this epoch 0.696384\n",
      " 34%|███▍      | 171/500 [1:58:58<7:37:58, 83.52s/it]  2020-07-20 05:09:23,564 train loss in this epoch 0.696424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 172/500 [1:59:04<5:28:49, 60.15s/it]2020-07-20 05:09:29,561 train loss in this epoch 0.696364\n",
      " 35%|███▍      | 173/500 [1:59:10<3:59:16, 43.90s/it]2020-07-20 05:09:35,416 train loss in this epoch 0.696406\n",
      " 35%|███▍      | 174/500 [1:59:16<2:56:31, 32.49s/it]2020-07-20 05:09:41,113 train loss in this epoch 0.696442\n",
      " 35%|███▌      | 175/500 [1:59:21<2:12:26, 24.45s/it]2020-07-20 05:09:46,912 train loss in this epoch 0.696386\n",
      " 35%|███▌      | 176/500 [1:59:27<1:41:49, 18.86s/it]2020-07-20 05:09:52,579 train loss in this epoch 0.696398\n",
      " 35%|███▌      | 177/500 [1:59:33<1:20:12, 14.90s/it]2020-07-20 05:09:58,689 train loss in this epoch 0.696417\n",
      " 36%|███▌      | 178/500 [1:59:39<1:05:48, 12.26s/it]2020-07-20 05:10:04,527 train loss in this epoch 0.696398\n",
      " 36%|███▌      | 179/500 [1:59:45<55:17, 10.33s/it]  2020-07-20 05:10:10,175 train loss in this epoch 0.696474\n",
      "2020-07-20 05:10:10,178 epoch 179, checkpoint!\n",
      "2020-07-20 05:15:26,366 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 05:15:26,924 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 05:16:11,215 using threshold -0.7295\n",
      "2020-07-20 05:16:11,703 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 36%|███▌      | 180/500 [2:05:52<10:26:04, 117.39s/it]2020-07-20 05:16:17,385 train loss in this epoch 0.696394\n",
      " 36%|███▌      | 181/500 [2:05:58<7:25:56, 83.88s/it]  2020-07-20 05:16:23,069 train loss in this epoch 0.696403\n",
      " 36%|███▋      | 182/500 [2:06:03<5:20:12, 60.42s/it]2020-07-20 05:16:29,075 train loss in this epoch 0.696383\n",
      " 37%|███▋      | 183/500 [2:06:09<3:52:57, 44.09s/it]2020-07-20 05:16:35,002 train loss in this epoch 0.696418\n",
      " 37%|███▋      | 184/500 [2:06:15<2:51:55, 32.64s/it]2020-07-20 05:16:40,937 train loss in this epoch 0.696455\n",
      " 37%|███▋      | 185/500 [2:06:21<2:09:19, 24.63s/it]2020-07-20 05:16:46,508 train loss in this epoch 0.696366\n",
      " 37%|███▋      | 186/500 [2:06:27<1:38:58, 18.91s/it]2020-07-20 05:16:52,350 train loss in this epoch 0.696368\n",
      " 37%|███▋      | 187/500 [2:06:33<1:18:12, 14.99s/it]2020-07-20 05:16:57,848 train loss in this epoch 0.696405\n",
      " 38%|███▊      | 188/500 [2:06:38<1:03:08, 12.14s/it]2020-07-20 05:17:03,480 train loss in this epoch 0.696369\n",
      " 38%|███▊      | 189/500 [2:06:44<52:49, 10.19s/it]  2020-07-20 05:17:09,399 train loss in this epoch 0.696442\n",
      "2020-07-20 05:17:09,400 epoch 189, checkpoint!\n",
      "2020-07-20 05:22:24,229 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 05:22:24,788 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 05:23:08,966 using threshold -0.7295\n",
      "2020-07-20 05:23:09,207 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 38%|███▊      | 190/500 [2:12:49<10:03:43, 116.85s/it]2020-07-20 05:23:15,489 train loss in this epoch 0.696388\n",
      " 38%|███▊      | 191/500 [2:12:56<7:10:57, 83.68s/it]  2020-07-20 05:23:21,509 train loss in this epoch 0.696417\n",
      " 38%|███▊      | 192/500 [2:13:02<5:09:57, 60.38s/it]2020-07-20 05:23:27,504 train loss in this epoch 0.696497\n",
      " 39%|███▊      | 193/500 [2:13:08<3:45:28, 44.07s/it]2020-07-20 05:23:33,411 train loss in this epoch 0.696348\n",
      " 39%|███▉      | 194/500 [2:13:14<2:46:21, 32.62s/it]2020-07-20 05:23:38,795 train loss in this epoch 0.696389\n",
      " 39%|███▉      | 195/500 [2:13:19<2:04:16, 24.45s/it]2020-07-20 05:23:44,504 train loss in this epoch 0.696442\n",
      " 39%|███▉      | 196/500 [2:13:25<1:35:23, 18.83s/it]2020-07-20 05:23:50,312 train loss in this epoch 0.696379\n",
      " 39%|███▉      | 197/500 [2:13:31<1:15:20, 14.92s/it]2020-07-20 05:23:55,897 train loss in this epoch 0.696431\n",
      " 40%|███▉      | 198/500 [2:13:36<1:01:00, 12.12s/it]2020-07-20 05:24:02,073 train loss in this epoch 0.696387\n",
      " 40%|███▉      | 199/500 [2:13:42<51:51, 10.34s/it]  2020-07-20 05:24:07,905 train loss in this epoch 0.696477\n",
      "2020-07-20 05:24:07,907 epoch 199, checkpoint!\n",
      "2020-07-20 05:29:23,299 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 05:29:23,857 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 05:30:08,042 using threshold -0.7295\n",
      "2020-07-20 05:30:08,433 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 40%|████      | 200/500 [2:19:49<9:45:43, 117.14s/it]2020-07-20 05:30:14,155 train loss in this epoch 0.696355\n",
      " 40%|████      | 201/500 [2:19:54<6:57:11, 83.72s/it] 2020-07-20 05:30:19,865 train loss in this epoch 0.696327\n",
      " 40%|████      | 202/500 [2:20:00<4:59:33, 60.32s/it]2020-07-20 05:30:25,984 train loss in this epoch 0.696369\n",
      " 41%|████      | 203/500 [2:20:06<3:38:04, 44.06s/it]2020-07-20 05:30:32,067 train loss in this epoch 0.696286\n",
      " 41%|████      | 204/500 [2:20:12<2:41:08, 32.66s/it]2020-07-20 05:30:38,037 train loss in this epoch 0.696472\n",
      " 41%|████      | 205/500 [2:20:18<2:01:13, 24.66s/it]2020-07-20 05:30:43,909 train loss in this epoch 0.696355\n",
      " 41%|████      | 206/500 [2:20:24<1:33:12, 19.02s/it]2020-07-20 05:30:49,975 train loss in this epoch 0.696418\n",
      " 41%|████▏     | 207/500 [2:20:30<1:13:54, 15.13s/it]2020-07-20 05:30:55,692 train loss in this epoch 0.696413\n",
      " 42%|████▏     | 208/500 [2:20:36<59:54, 12.31s/it]  2020-07-20 05:31:01,479 train loss in this epoch 0.696446\n",
      " 42%|████▏     | 209/500 [2:20:42<50:12, 10.35s/it]2020-07-20 05:31:07,432 train loss in this epoch 0.696461\n",
      "2020-07-20 05:31:07,435 epoch 209, checkpoint!\n",
      "2020-07-20 05:36:20,884 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 05:36:21,444 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 05:37:07,647 using threshold -0.7295\n",
      "2020-07-20 05:37:08,107 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 42%|████▏     | 210/500 [2:26:48<9:26:38, 117.24s/it]2020-07-20 05:37:13,873 train loss in this epoch 0.696454\n",
      " 42%|████▏     | 211/500 [2:26:54<6:43:36, 83.79s/it] 2020-07-20 05:37:19,860 train loss in this epoch 0.696391\n",
      " 42%|████▏     | 212/500 [2:27:00<4:50:10, 60.45s/it]2020-07-20 05:37:25,378 train loss in this epoch 0.696416\n",
      " 43%|████▎     | 213/500 [2:27:06<3:30:19, 43.97s/it]2020-07-20 05:37:30,840 train loss in this epoch 0.696415\n",
      " 43%|████▎     | 214/500 [2:27:11<2:34:31, 32.42s/it]2020-07-20 05:37:36,362 train loss in this epoch 0.696414\n",
      " 43%|████▎     | 215/500 [2:27:17<1:55:39, 24.35s/it]2020-07-20 05:37:42,119 train loss in this epoch 0.696441\n",
      " 43%|████▎     | 216/500 [2:27:22<1:28:51, 18.77s/it]2020-07-20 05:37:47,950 train loss in this epoch 0.696424\n",
      " 43%|████▎     | 217/500 [2:27:28<1:10:13, 14.89s/it]2020-07-20 05:37:53,847 train loss in this epoch 0.696396\n",
      " 44%|████▎     | 218/500 [2:27:34<57:18, 12.19s/it]  2020-07-20 05:37:59,983 train loss in this epoch 0.696363\n",
      " 44%|████▍     | 219/500 [2:27:40<48:35, 10.38s/it]2020-07-20 05:38:05,935 train loss in this epoch 0.696436\n",
      "2020-07-20 05:38:05,938 epoch 219, checkpoint!\n",
      "2020-07-20 05:43:24,098 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 05:43:24,657 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 05:44:09,805 using threshold -0.7295\n",
      "2020-07-20 05:44:10,047 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 44%|████▍     | 220/500 [2:33:50<9:11:58, 118.28s/it]2020-07-20 05:44:15,911 train loss in this epoch 0.696435\n",
      " 44%|████▍     | 221/500 [2:33:56<6:33:11, 84.56s/it] 2020-07-20 05:44:21,933 train loss in this epoch 0.696464\n",
      " 44%|████▍     | 222/500 [2:34:02<4:42:36, 61.00s/it]2020-07-20 05:44:27,282 train loss in this epoch 0.696385\n",
      " 45%|████▍     | 223/500 [2:34:08<3:24:31, 44.30s/it]2020-07-20 05:44:32,980 train loss in this epoch 0.696436\n",
      " 45%|████▍     | 224/500 [2:34:13<2:30:30, 32.72s/it]2020-07-20 05:44:38,920 train loss in this epoch 0.696393\n",
      " 45%|████▌     | 225/500 [2:34:19<1:53:08, 24.69s/it]2020-07-20 05:44:44,749 train loss in this epoch 0.696416\n",
      " 45%|████▌     | 226/500 [2:34:25<1:26:53, 19.03s/it]2020-07-20 05:44:50,370 train loss in this epoch 0.696420\n",
      " 45%|████▌     | 227/500 [2:34:31<1:08:16, 15.01s/it]2020-07-20 05:44:55,957 train loss in this epoch 0.696412\n",
      " 46%|████▌     | 228/500 [2:34:36<55:13, 12.18s/it]  2020-07-20 05:45:02,418 train loss in this epoch 0.696434\n",
      " 46%|████▌     | 229/500 [2:34:43<47:15, 10.46s/it]2020-07-20 05:45:08,322 train loss in this epoch 0.696385\n",
      "2020-07-20 05:45:08,323 epoch 229, checkpoint!\n",
      "2020-07-20 05:50:24,660 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 05:50:25,220 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 05:51:10,181 using threshold -0.7295\n",
      "2020-07-20 05:51:10,424 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 46%|████▌     | 230/500 [2:40:51<8:49:46, 117.73s/it]2020-07-20 05:51:16,305 train loss in this epoch 0.696417\n",
      " 46%|████▌     | 231/500 [2:40:57<6:17:22, 84.17s/it] 2020-07-20 05:51:22,146 train loss in this epoch 0.696395\n",
      " 46%|████▋     | 232/500 [2:41:02<4:31:00, 60.67s/it]2020-07-20 05:51:27,986 train loss in this epoch 0.696461\n",
      " 47%|████▋     | 233/500 [2:41:08<3:16:47, 44.22s/it]2020-07-20 05:51:34,002 train loss in this epoch 0.696376\n",
      " 47%|████▋     | 234/500 [2:41:14<2:25:14, 32.76s/it]2020-07-20 05:51:40,349 train loss in this epoch 0.696432\n",
      " 47%|████▋     | 235/500 [2:41:21<1:49:41, 24.84s/it]2020-07-20 05:51:45,938 train loss in this epoch 0.696409\n",
      " 47%|████▋     | 236/500 [2:41:26<1:23:52, 19.06s/it]2020-07-20 05:51:51,787 train loss in this epoch 0.696456\n",
      " 47%|████▋     | 237/500 [2:41:32<1:06:10, 15.10s/it]2020-07-20 05:51:57,369 train loss in this epoch 0.696421\n",
      " 48%|████▊     | 238/500 [2:41:38<53:27, 12.24s/it]  2020-07-20 05:52:03,273 train loss in this epoch 0.696349\n",
      " 48%|████▊     | 239/500 [2:41:44<44:59, 10.34s/it]2020-07-20 05:52:08,973 train loss in this epoch 0.696443\n",
      "2020-07-20 05:52:08,975 epoch 239, checkpoint!\n",
      "2020-07-20 05:57:22,547 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 05:57:23,107 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 05:58:08,361 using threshold -0.7295\n",
      "2020-07-20 05:58:08,745 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 48%|████▊     | 240/500 [2:47:49<8:26:29, 116.88s/it]2020-07-20 05:58:14,396 train loss in this epoch 0.696410\n",
      " 48%|████▊     | 241/500 [2:47:55<6:00:29, 83.51s/it] 2020-07-20 05:58:20,325 train loss in this epoch 0.696421\n",
      " 48%|████▊     | 242/500 [2:48:01<4:19:01, 60.24s/it]2020-07-20 05:58:26,167 train loss in this epoch 0.696399\n",
      " 49%|████▊     | 243/500 [2:48:06<3:08:07, 43.92s/it]2020-07-20 05:58:31,924 train loss in this epoch 0.696467\n",
      " 49%|████▉     | 244/500 [2:48:12<2:18:32, 32.47s/it]2020-07-20 05:58:38,054 train loss in this epoch 0.696435\n",
      " 49%|████▉     | 245/500 [2:48:18<1:44:24, 24.57s/it]2020-07-20 05:58:43,965 train loss in this epoch 0.696488\n",
      " 49%|████▉     | 246/500 [2:48:24<1:20:18, 18.97s/it]2020-07-20 05:58:49,968 train loss in this epoch 0.696365\n",
      " 49%|████▉     | 247/500 [2:48:30<1:03:35, 15.08s/it]2020-07-20 05:58:55,824 train loss in this epoch 0.696418\n",
      " 50%|████▉     | 248/500 [2:48:36<51:42, 12.31s/it]  2020-07-20 05:59:01,608 train loss in this epoch 0.696470\n",
      " 50%|████▉     | 249/500 [2:48:42<43:18, 10.35s/it]2020-07-20 05:59:07,452 train loss in this epoch 0.696452\n",
      "2020-07-20 05:59:07,455 epoch 249, checkpoint!\n",
      "2020-07-20 06:04:25,542 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 06:04:26,103 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 06:05:11,387 using threshold -0.7295\n",
      "2020-07-20 06:05:11,744 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 50%|█████     | 250/500 [2:54:52<8:12:52, 118.29s/it]2020-07-20 06:05:17,238 train loss in this epoch 0.696385\n",
      " 50%|█████     | 251/500 [2:54:57<5:50:28, 84.45s/it] 2020-07-20 06:05:22,779 train loss in this epoch 0.696420\n",
      " 50%|█████     | 252/500 [2:55:03<4:11:12, 60.78s/it]2020-07-20 06:05:28,310 train loss in this epoch 0.696375\n",
      " 51%|█████     | 253/500 [2:55:09<3:01:58, 44.20s/it]2020-07-20 06:05:34,267 train loss in this epoch 0.696449\n",
      " 51%|█████     | 254/500 [2:55:15<2:14:11, 32.73s/it]2020-07-20 06:05:39,765 train loss in this epoch 0.696446\n",
      " 51%|█████     | 255/500 [2:55:20<1:40:17, 24.56s/it]2020-07-20 06:05:45,278 train loss in this epoch 0.696437\n",
      " 51%|█████     | 256/500 [2:55:26<1:16:38, 18.85s/it]2020-07-20 06:05:50,814 train loss in this epoch 0.696374\n",
      " 51%|█████▏    | 257/500 [2:55:31<1:00:09, 14.85s/it]2020-07-20 06:05:56,725 train loss in this epoch 0.696435\n",
      " 52%|█████▏    | 258/500 [2:55:37<49:05, 12.17s/it]  2020-07-20 06:06:02,540 train loss in this epoch 0.696405\n",
      " 52%|█████▏    | 259/500 [2:55:43<41:13, 10.26s/it]2020-07-20 06:06:08,763 train loss in this epoch 0.696443\n",
      "2020-07-20 06:06:08,766 epoch 259, checkpoint!\n",
      "2020-07-20 06:11:22,478 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 06:11:23,037 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 06:12:09,050 using threshold -0.7295\n",
      "2020-07-20 06:12:09,502 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 52%|█████▏    | 260/500 [3:01:50<7:49:05, 117.27s/it]2020-07-20 06:12:15,403 train loss in this epoch 0.696367\n",
      " 52%|█████▏    | 261/500 [3:01:56<5:34:02, 83.86s/it] 2020-07-20 06:12:21,416 train loss in this epoch 0.696357\n",
      " 52%|█████▏    | 262/500 [3:02:02<4:00:00, 60.51s/it]2020-07-20 06:12:26,916 train loss in this epoch 0.696426\n",
      " 53%|█████▎    | 263/500 [3:02:07<2:53:49, 44.01s/it]2020-07-20 06:12:32,783 train loss in this epoch 0.696437\n",
      " 53%|█████▎    | 264/500 [3:02:13<2:08:05, 32.56s/it]2020-07-20 06:12:38,910 train loss in this epoch 0.696418\n",
      " 53%|█████▎    | 265/500 [3:02:19<1:36:28, 24.63s/it]2020-07-20 06:12:44,660 train loss in this epoch 0.696430\n",
      " 53%|█████▎    | 266/500 [3:02:25<1:13:58, 18.97s/it]2020-07-20 06:12:50,273 train loss in this epoch 0.696433\n",
      " 53%|█████▎    | 267/500 [3:02:31<58:05, 14.96s/it]  2020-07-20 06:12:56,215 train loss in this epoch 0.696473\n",
      " 54%|█████▎    | 268/500 [3:02:36<47:23, 12.26s/it]2020-07-20 06:13:02,241 train loss in this epoch 0.696389\n",
      " 54%|█████▍    | 269/500 [3:02:42<39:59, 10.39s/it]2020-07-20 06:13:08,019 train loss in this epoch 0.696393\n",
      "2020-07-20 06:13:08,021 epoch 269, checkpoint!\n",
      "2020-07-20 06:18:22,608 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 06:18:23,166 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 06:19:07,620 using threshold -0.7295\n",
      "2020-07-20 06:19:07,863 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 54%|█████▍    | 270/500 [3:08:48<7:28:20, 116.96s/it]2020-07-20 06:19:13,723 train loss in this epoch 0.696336\n",
      " 54%|█████▍    | 271/500 [3:08:54<5:19:10, 83.63s/it] 2020-07-20 06:19:19,384 train loss in this epoch 0.696474\n",
      " 54%|█████▍    | 272/500 [3:09:00<3:48:54, 60.24s/it]2020-07-20 06:19:25,092 train loss in this epoch 0.696426\n",
      " 55%|█████▍    | 273/500 [3:09:05<2:46:00, 43.88s/it]2020-07-20 06:19:30,941 train loss in this epoch 0.696435\n",
      " 55%|█████▍    | 274/500 [3:09:11<2:02:18, 32.47s/it]2020-07-20 06:19:36,799 train loss in this epoch 0.696447\n",
      " 55%|█████▌    | 275/500 [3:09:17<1:31:49, 24.49s/it]2020-07-20 06:19:42,511 train loss in this epoch 0.696427\n",
      " 55%|█████▌    | 276/500 [3:09:23<1:10:23, 18.85s/it]2020-07-20 06:19:48,392 train loss in this epoch 0.696443\n",
      " 55%|█████▌    | 277/500 [3:09:29<55:36, 14.96s/it]  2020-07-20 06:19:54,244 train loss in this epoch 0.696477\n",
      " 56%|█████▌    | 278/500 [3:09:34<45:14, 12.23s/it]2020-07-20 06:19:59,797 train loss in this epoch 0.696434\n",
      " 56%|█████▌    | 279/500 [3:09:40<37:40, 10.23s/it]2020-07-20 06:20:05,601 train loss in this epoch 0.696469\n",
      "2020-07-20 06:20:05,603 epoch 279, checkpoint!\n",
      "2020-07-20 06:25:19,714 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 06:25:20,272 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 06:26:04,837 using threshold -0.7295\n",
      "2020-07-20 06:26:05,079 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 56%|█████▌    | 280/500 [3:15:45<7:08:03, 116.74s/it]2020-07-20 06:26:10,876 train loss in this epoch 0.696321\n",
      " 56%|█████▌    | 281/500 [3:15:51<5:04:37, 83.46s/it] 2020-07-20 06:26:16,976 train loss in this epoch 0.696392\n",
      " 56%|█████▋    | 282/500 [3:15:57<3:38:54, 60.25s/it]2020-07-20 06:26:22,805 train loss in this epoch 0.696442\n",
      " 57%|█████▋    | 283/500 [3:16:03<2:38:51, 43.92s/it]2020-07-20 06:26:28,875 train loss in this epoch 0.696442\n",
      " 57%|█████▋    | 284/500 [3:16:09<1:57:14, 32.57s/it]2020-07-20 06:26:34,744 train loss in this epoch 0.696381\n",
      " 57%|█████▋    | 285/500 [3:16:15<1:28:00, 24.56s/it]2020-07-20 06:26:40,599 train loss in this epoch 0.696418\n",
      " 57%|█████▋    | 286/500 [3:16:21<1:07:34, 18.95s/it]2020-07-20 06:26:46,215 train loss in this epoch 0.696352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 287/500 [3:16:26<53:03, 14.95s/it]  2020-07-20 06:26:52,453 train loss in this epoch 0.696417\n",
      " 58%|█████▊    | 288/500 [3:16:33<43:34, 12.33s/it]2020-07-20 06:26:58,337 train loss in this epoch 0.696448\n",
      " 58%|█████▊    | 289/500 [3:16:39<36:34, 10.40s/it]2020-07-20 06:27:04,230 train loss in this epoch 0.696426\n",
      "2020-07-20 06:27:04,231 epoch 289, checkpoint!\n",
      "2020-07-20 06:32:21,150 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 06:32:21,709 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 06:33:04,847 using threshold -0.7295\n",
      "2020-07-20 06:33:05,112 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 58%|█████▊    | 290/500 [3:22:45<6:50:35, 117.31s/it]2020-07-20 06:33:10,765 train loss in this epoch 0.696385\n",
      " 58%|█████▊    | 291/500 [3:22:51<4:51:57, 83.81s/it] 2020-07-20 06:33:16,687 train loss in this epoch 0.696448\n",
      " 58%|█████▊    | 292/500 [3:22:57<3:29:32, 60.45s/it]2020-07-20 06:33:22,219 train loss in this epoch 0.696368\n",
      " 59%|█████▊    | 293/500 [3:23:02<2:31:42, 43.97s/it]2020-07-20 06:33:27,928 train loss in this epoch 0.696470\n",
      " 59%|█████▉    | 294/500 [3:23:08<1:51:33, 32.49s/it]2020-07-20 06:33:33,725 train loss in this epoch 0.696405\n",
      " 59%|█████▉    | 295/500 [3:23:14<1:23:39, 24.48s/it]2020-07-20 06:33:39,377 train loss in this epoch 0.696475\n",
      " 59%|█████▉    | 296/500 [3:23:20<1:04:02, 18.83s/it]2020-07-20 06:33:45,375 train loss in this epoch 0.696431\n",
      " 59%|█████▉    | 297/500 [3:23:26<50:41, 14.98s/it]  2020-07-20 06:33:51,384 train loss in this epoch 0.696427\n",
      " 60%|█████▉    | 298/500 [3:23:32<41:22, 12.29s/it]2020-07-20 06:33:57,247 train loss in this epoch 0.696384\n",
      " 60%|█████▉    | 299/500 [3:23:38<34:42, 10.36s/it]2020-07-20 06:34:03,195 train loss in this epoch 0.696397\n",
      "2020-07-20 06:34:03,198 epoch 299, checkpoint!\n",
      "2020-07-20 06:39:17,966 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 06:39:18,524 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 06:40:04,237 using threshold -0.7295\n",
      "2020-07-20 06:40:04,478 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 60%|██████    | 300/500 [3:29:45<6:31:24, 117.42s/it]2020-07-20 06:40:10,347 train loss in this epoch 0.696405\n",
      " 60%|██████    | 301/500 [3:29:51<4:38:27, 83.96s/it] 2020-07-20 06:40:16,168 train loss in this epoch 0.696380\n",
      " 60%|██████    | 302/500 [3:29:56<3:19:42, 60.52s/it]2020-07-20 06:40:21,814 train loss in this epoch 0.696348\n",
      " 61%|██████    | 303/500 [3:30:02<2:24:38, 44.06s/it]2020-07-20 06:40:27,754 train loss in this epoch 0.696369\n",
      " 61%|██████    | 304/500 [3:30:08<1:46:33, 32.62s/it]2020-07-20 06:40:33,841 train loss in this epoch 0.696358\n",
      " 61%|██████    | 305/500 [3:30:14<1:20:08, 24.66s/it]2020-07-20 06:40:39,800 train loss in this epoch 0.696405\n",
      " 61%|██████    | 306/500 [3:30:20<1:01:35, 19.05s/it]2020-07-20 06:40:45,898 train loss in this epoch 0.696374\n",
      " 61%|██████▏   | 307/500 [3:30:26<48:46, 15.16s/it]  2020-07-20 06:40:51,727 train loss in this epoch 0.696322\n",
      " 62%|██████▏   | 308/500 [3:30:32<39:33, 12.36s/it]2020-07-20 06:40:57,638 train loss in this epoch 0.696474\n",
      " 62%|██████▏   | 309/500 [3:30:38<33:11, 10.43s/it]2020-07-20 06:41:03,261 train loss in this epoch 0.696444\n",
      "2020-07-20 06:41:03,263 epoch 309, checkpoint!\n",
      "2020-07-20 06:46:19,262 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 06:46:19,823 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 06:47:05,497 using threshold -0.7295\n",
      "2020-07-20 06:47:05,968 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 62%|██████▏   | 310/500 [3:36:46<6:13:01, 117.80s/it]2020-07-20 06:47:11,808 train loss in this epoch 0.696350\n",
      " 62%|██████▏   | 311/500 [3:36:52<4:25:15, 84.21s/it] 2020-07-20 06:47:17,664 train loss in this epoch 0.696414\n",
      " 62%|██████▏   | 312/500 [3:36:58<3:10:12, 60.70s/it]2020-07-20 06:47:23,185 train loss in this epoch 0.696395\n",
      " 63%|██████▎   | 313/500 [3:37:03<2:17:35, 44.15s/it]2020-07-20 06:47:28,836 train loss in this epoch 0.696373\n",
      " 63%|██████▎   | 314/500 [3:37:09<1:41:03, 32.60s/it]2020-07-20 06:47:34,782 train loss in this epoch 0.696379\n",
      " 63%|██████▎   | 315/500 [3:37:15<1:15:51, 24.60s/it]2020-07-20 06:47:40,720 train loss in this epoch 0.696443\n",
      " 63%|██████▎   | 316/500 [3:37:21<58:16, 19.00s/it]  2020-07-20 06:47:46,671 train loss in this epoch 0.696416\n",
      " 63%|██████▎   | 317/500 [3:37:27<46:01, 15.09s/it]2020-07-20 06:47:52,575 train loss in this epoch 0.696398\n",
      " 64%|██████▎   | 318/500 [3:37:33<37:24, 12.33s/it]2020-07-20 06:47:58,687 train loss in this epoch 0.696395\n",
      " 64%|██████▍   | 319/500 [3:37:39<31:34, 10.47s/it]2020-07-20 06:48:04,211 train loss in this epoch 0.696433\n",
      "2020-07-20 06:48:04,214 epoch 319, checkpoint!\n",
      "2020-07-20 06:53:21,987 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 06:53:22,545 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 06:54:07,980 using threshold -0.7295\n",
      "2020-07-20 06:54:08,422 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 64%|██████▍   | 320/500 [3:43:49<5:54:44, 118.25s/it]2020-07-20 06:54:14,216 train loss in this epoch 0.696355\n",
      " 64%|██████▍   | 321/500 [3:43:54<4:12:07, 84.51s/it] 2020-07-20 06:54:19,871 train loss in this epoch 0.696447\n",
      " 64%|██████▍   | 322/500 [3:44:00<3:00:32, 60.85s/it]2020-07-20 06:54:25,910 train loss in this epoch 0.696451\n",
      " 65%|██████▍   | 323/500 [3:44:06<2:11:00, 44.41s/it]2020-07-20 06:54:31,741 train loss in this epoch 0.696419\n",
      " 65%|██████▍   | 324/500 [3:44:12<1:36:19, 32.84s/it]2020-07-20 06:54:37,534 train loss in this epoch 0.696379\n",
      " 65%|██████▌   | 325/500 [3:44:18<1:12:06, 24.72s/it]2020-07-20 06:54:43,207 train loss in this epoch 0.696465\n",
      " 65%|██████▌   | 326/500 [3:44:23<55:07, 19.01s/it]  2020-07-20 06:54:49,303 train loss in this epoch 0.696436\n",
      " 65%|██████▌   | 327/500 [3:44:30<43:38, 15.13s/it]2020-07-20 06:54:55,243 train loss in this epoch 0.696361\n",
      " 66%|██████▌   | 328/500 [3:44:35<35:28, 12.38s/it]2020-07-20 06:55:01,183 train loss in this epoch 0.696423\n",
      " 66%|██████▌   | 329/500 [3:44:41<29:46, 10.45s/it]2020-07-20 06:55:07,130 train loss in this epoch 0.696386\n",
      "2020-07-20 06:55:07,131 epoch 329, checkpoint!\n",
      "2020-07-20 07:00:24,553 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 07:00:25,109 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 07:01:10,609 using threshold -0.7295\n",
      "2020-07-20 07:01:10,851 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 66%|██████▌   | 330/500 [3:50:51<5:34:56, 118.21s/it]2020-07-20 07:01:16,456 train loss in this epoch 0.696459\n",
      " 66%|██████▌   | 331/500 [3:50:57<3:57:48, 84.43s/it] 2020-07-20 07:01:22,323 train loss in this epoch 0.696396\n",
      " 66%|██████▋   | 332/500 [3:51:03<2:50:24, 60.86s/it]2020-07-20 07:01:28,051 train loss in this epoch 0.696383\n",
      " 67%|██████▋   | 333/500 [3:51:08<2:03:21, 44.32s/it]2020-07-20 07:01:33,451 train loss in this epoch 0.696417\n",
      " 67%|██████▋   | 334/500 [3:51:14<1:30:19, 32.64s/it]2020-07-20 07:01:39,407 train loss in this epoch 0.696461\n",
      " 67%|██████▋   | 335/500 [3:51:20<1:07:45, 24.64s/it]2020-07-20 07:01:45,520 train loss in this epoch 0.696368\n",
      " 67%|██████▋   | 336/500 [3:51:26<52:09, 19.08s/it]  2020-07-20 07:01:51,498 train loss in this epoch 0.696342\n",
      " 67%|██████▋   | 337/500 [3:51:32<41:09, 15.15s/it]2020-07-20 07:01:57,323 train loss in this epoch 0.696405\n",
      " 68%|██████▊   | 338/500 [3:51:38<33:21, 12.35s/it]2020-07-20 07:02:02,980 train loss in this epoch 0.696396\n",
      " 68%|██████▊   | 339/500 [3:51:43<27:45, 10.34s/it]2020-07-20 07:02:09,111 train loss in this epoch 0.696381\n",
      "2020-07-20 07:02:09,113 epoch 339, checkpoint!\n",
      "2020-07-20 07:07:25,548 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 07:07:26,106 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 07:08:12,482 using threshold -0.7295\n",
      "2020-07-20 07:08:12,724 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 68%|██████▊   | 340/500 [3:57:53<5:15:06, 118.16s/it]2020-07-20 07:08:18,464 train loss in this epoch 0.696364\n",
      " 68%|██████▊   | 341/500 [3:57:59<3:43:45, 84.44s/it] 2020-07-20 07:08:24,264 train loss in this epoch 0.696406\n",
      " 68%|██████▊   | 342/500 [3:58:05<2:40:13, 60.85s/it]2020-07-20 07:08:29,821 train loss in this epoch 0.696457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 343/500 [3:58:10<1:55:48, 44.26s/it]2020-07-20 07:08:35,692 train loss in this epoch 0.696424\n",
      " 69%|██████▉   | 344/500 [3:58:16<1:25:07, 32.74s/it]2020-07-20 07:08:41,148 train loss in this epoch 0.696493\n",
      " 69%|██████▉   | 345/500 [3:58:21<1:03:26, 24.56s/it]2020-07-20 07:08:46,774 train loss in this epoch 0.696445\n",
      " 69%|██████▉   | 346/500 [3:58:27<48:27, 18.88s/it]  2020-07-20 07:08:52,716 train loss in this epoch 0.696337\n",
      " 69%|██████▉   | 347/500 [3:58:33<38:14, 15.00s/it]2020-07-20 07:08:58,877 train loss in this epoch 0.696429\n",
      " 70%|██████▉   | 348/500 [3:58:39<31:16, 12.35s/it]2020-07-20 07:09:04,791 train loss in this epoch 0.696371\n",
      " 70%|██████▉   | 349/500 [3:58:45<26:12, 10.42s/it]2020-07-20 07:09:10,689 train loss in this epoch 0.696466\n",
      "2020-07-20 07:09:10,692 epoch 349, checkpoint!\n",
      "2020-07-20 07:14:23,724 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 07:14:24,284 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 07:15:09,605 using threshold -0.7295\n",
      "2020-07-20 07:15:09,845 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 70%|███████   | 350/500 [4:04:50<4:52:01, 116.81s/it]2020-07-20 07:15:15,848 train loss in this epoch 0.696384\n",
      " 70%|███████   | 351/500 [4:04:56<3:27:31, 83.57s/it] 2020-07-20 07:15:21,646 train loss in this epoch 0.696454\n",
      " 70%|███████   | 352/500 [4:05:02<2:28:34, 60.24s/it]2020-07-20 07:15:27,458 train loss in this epoch 0.696435\n",
      " 71%|███████   | 353/500 [4:05:08<1:47:34, 43.91s/it]2020-07-20 07:15:33,187 train loss in this epoch 0.696401\n",
      " 71%|███████   | 354/500 [4:05:13<1:18:58, 32.45s/it]2020-07-20 07:15:39,020 train loss in this epoch 0.696349\n",
      " 71%|███████   | 355/500 [4:05:19<59:07, 24.47s/it]  2020-07-20 07:15:44,629 train loss in this epoch 0.696422\n",
      " 71%|███████   | 356/500 [4:05:25<45:08, 18.81s/it]2020-07-20 07:15:50,203 train loss in this epoch 0.696379\n",
      " 71%|███████▏  | 357/500 [4:05:30<35:22, 14.84s/it]2020-07-20 07:15:56,143 train loss in this epoch 0.696389\n",
      " 72%|███████▏  | 358/500 [4:05:36<28:48, 12.17s/it]2020-07-20 07:16:02,111 train loss in this epoch 0.696411\n",
      " 72%|███████▏  | 359/500 [4:05:42<24:13, 10.31s/it]2020-07-20 07:16:07,631 train loss in this epoch 0.696436\n",
      "2020-07-20 07:16:07,634 epoch 359, checkpoint!\n",
      "2020-07-20 07:21:22,059 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 07:21:22,618 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 07:22:07,730 using threshold -0.7295\n",
      "2020-07-20 07:22:07,972 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 72%|███████▏  | 360/500 [4:11:48<4:32:56, 116.97s/it]2020-07-20 07:22:13,799 train loss in this epoch 0.696371\n",
      " 72%|███████▏  | 361/500 [4:11:54<3:13:44, 83.63s/it] 2020-07-20 07:22:19,768 train loss in this epoch 0.696367\n",
      " 72%|███████▏  | 362/500 [4:12:00<2:18:45, 60.33s/it]2020-07-20 07:22:25,636 train loss in this epoch 0.696410\n",
      " 73%|███████▎  | 363/500 [4:12:06<1:40:27, 43.99s/it]2020-07-20 07:22:31,728 train loss in this epoch 0.696362\n",
      " 73%|███████▎  | 364/500 [4:12:12<1:13:56, 32.62s/it]2020-07-20 07:22:37,499 train loss in this epoch 0.696430\n",
      " 73%|███████▎  | 365/500 [4:12:18<55:16, 24.57s/it]  2020-07-20 07:22:43,127 train loss in this epoch 0.696362\n",
      " 73%|███████▎  | 366/500 [4:12:23<42:10, 18.89s/it]2020-07-20 07:22:49,155 train loss in this epoch 0.696372\n",
      " 73%|███████▎  | 367/500 [4:12:29<33:18, 15.03s/it]2020-07-20 07:22:55,065 train loss in this epoch 0.696407\n",
      " 74%|███████▎  | 368/500 [4:12:35<27:02, 12.29s/it]2020-07-20 07:23:00,676 train loss in this epoch 0.696416\n",
      " 74%|███████▍  | 369/500 [4:12:41<22:27, 10.29s/it]2020-07-20 07:23:06,368 train loss in this epoch 0.696468\n",
      "2020-07-20 07:23:06,370 epoch 369, checkpoint!\n",
      "2020-07-20 07:28:24,723 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 07:28:25,604 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 07:29:11,206 using threshold -0.7295\n",
      "2020-07-20 07:29:11,447 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 74%|███████▍  | 370/500 [4:18:52<4:16:36, 118.43s/it]2020-07-20 07:29:17,317 train loss in this epoch 0.696363\n",
      " 74%|███████▍  | 371/500 [4:18:58<3:02:01, 84.66s/it] 2020-07-20 07:29:23,156 train loss in this epoch 0.696448\n",
      " 74%|███████▍  | 372/500 [4:19:03<2:10:10, 61.02s/it]2020-07-20 07:29:29,153 train loss in this epoch 0.696418\n",
      " 75%|███████▍  | 373/500 [4:19:09<1:34:12, 44.51s/it]2020-07-20 07:29:35,191 train loss in this epoch 0.696351\n",
      " 75%|███████▍  | 374/500 [4:19:15<1:09:14, 32.97s/it]2020-07-20 07:29:41,264 train loss in this epoch 0.696408\n",
      " 75%|███████▌  | 375/500 [4:19:22<51:52, 24.90s/it]  2020-07-20 07:29:47,240 train loss in this epoch 0.696388\n",
      " 75%|███████▌  | 376/500 [4:19:27<39:43, 19.22s/it]2020-07-20 07:29:53,125 train loss in this epoch 0.696366\n",
      " 75%|███████▌  | 377/500 [4:19:33<31:12, 15.22s/it]2020-07-20 07:29:59,224 train loss in this epoch 0.696388\n",
      " 76%|███████▌  | 378/500 [4:19:39<25:23, 12.48s/it]2020-07-20 07:30:05,103 train loss in this epoch 0.696402\n",
      " 76%|███████▌  | 379/500 [4:19:45<21:10, 10.50s/it]2020-07-20 07:30:10,648 train loss in this epoch 0.696371\n",
      "2020-07-20 07:30:10,650 epoch 379, checkpoint!\n",
      "2020-07-20 07:35:27,693 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 07:35:28,251 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 07:36:13,557 using threshold -0.7295\n",
      "2020-07-20 07:36:13,799 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 76%|███████▌  | 380/500 [4:25:54<3:55:55, 117.96s/it]2020-07-20 07:36:19,245 train loss in this epoch 0.696431\n",
      " 76%|███████▌  | 381/500 [4:25:59<2:47:00, 84.21s/it] 2020-07-20 07:36:25,379 train loss in this epoch 0.696413\n",
      " 76%|███████▋  | 382/500 [4:26:06<1:59:32, 60.78s/it]2020-07-20 07:36:31,292 train loss in this epoch 0.696405\n",
      " 77%|███████▋  | 383/500 [4:26:12<1:26:25, 44.32s/it]2020-07-20 07:36:37,338 train loss in this epoch 0.696417\n",
      " 77%|███████▋  | 384/500 [4:26:18<1:03:29, 32.84s/it]2020-07-20 07:36:43,059 train loss in this epoch 0.696422\n",
      " 77%|███████▋  | 385/500 [4:26:23<47:20, 24.70s/it]  2020-07-20 07:36:48,629 train loss in this epoch 0.696454\n",
      " 77%|███████▋  | 386/500 [4:26:29<36:01, 18.96s/it]2020-07-20 07:36:54,448 train loss in this epoch 0.696394\n",
      " 77%|███████▋  | 387/500 [4:26:35<28:17, 15.02s/it]2020-07-20 07:37:00,127 train loss in this epoch 0.696419\n",
      " 78%|███████▊  | 388/500 [4:26:40<22:48, 12.22s/it]2020-07-20 07:37:06,138 train loss in this epoch 0.696492\n",
      " 78%|███████▊  | 389/500 [4:26:46<19:09, 10.36s/it]2020-07-20 07:37:12,336 train loss in this epoch 0.696477\n",
      "2020-07-20 07:37:12,338 epoch 389, checkpoint!\n",
      "2020-07-20 07:42:27,478 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 07:42:28,037 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 07:43:12,250 using threshold -0.7295\n",
      "2020-07-20 07:43:12,492 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 78%|███████▊  | 390/500 [4:32:53<3:34:47, 117.16s/it]2020-07-20 07:43:18,299 train loss in this epoch 0.696397\n",
      " 78%|███████▊  | 391/500 [4:32:59<2:32:08, 83.75s/it] 2020-07-20 07:43:24,082 train loss in this epoch 0.696472\n",
      " 78%|███████▊  | 392/500 [4:33:04<1:48:38, 60.36s/it]2020-07-20 07:43:29,628 train loss in this epoch 0.696450\n",
      " 79%|███████▊  | 393/500 [4:33:10<1:18:19, 43.92s/it]2020-07-20 07:43:35,715 train loss in this epoch 0.696418\n",
      " 79%|███████▉  | 394/500 [4:33:16<57:32, 32.57s/it]  2020-07-20 07:43:41,721 train loss in this epoch 0.696394\n",
      " 79%|███████▉  | 395/500 [4:33:22<43:02, 24.60s/it]2020-07-20 07:43:47,620 train loss in this epoch 0.696400\n",
      " 79%|███████▉  | 396/500 [4:33:28<32:54, 18.99s/it]2020-07-20 07:43:53,578 train loss in this epoch 0.696420\n",
      " 79%|███████▉  | 397/500 [4:33:34<25:53, 15.08s/it]2020-07-20 07:43:59,538 train loss in this epoch 0.696445\n",
      " 80%|███████▉  | 398/500 [4:33:40<20:59, 12.34s/it]2020-07-20 07:44:05,047 train loss in this epoch 0.696436\n",
      " 80%|███████▉  | 399/500 [4:33:45<17:19, 10.29s/it]2020-07-20 07:44:10,586 train loss in this epoch 0.696482\n",
      "2020-07-20 07:44:10,589 epoch 399, checkpoint!\n",
      "2020-07-20 07:49:24,958 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 07:49:25,517 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 07:50:11,271 using threshold -0.7295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 07:50:11,514 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 80%|████████  | 400/500 [4:39:52<3:15:14, 117.15s/it]2020-07-20 07:50:17,130 train loss in this epoch 0.696410\n",
      " 80%|████████  | 401/500 [4:39:57<2:18:04, 83.69s/it] 2020-07-20 07:50:22,786 train loss in this epoch 0.696419\n",
      " 80%|████████  | 402/500 [4:40:03<1:38:27, 60.28s/it]2020-07-20 07:50:28,846 train loss in this epoch 0.696351\n",
      " 81%|████████  | 403/500 [4:40:09<1:11:09, 44.01s/it]2020-07-20 07:50:34,611 train loss in this epoch 0.696293\n",
      " 81%|████████  | 404/500 [4:40:15<52:03, 32.54s/it]  2020-07-20 07:50:40,100 train loss in this epoch 0.696429\n",
      " 81%|████████  | 405/500 [4:40:20<38:40, 24.42s/it]2020-07-20 07:50:45,609 train loss in this epoch 0.696385\n",
      " 81%|████████  | 406/500 [4:40:26<29:22, 18.75s/it]2020-07-20 07:50:51,135 train loss in this epoch 0.696423\n",
      " 81%|████████▏ | 407/500 [4:40:31<22:54, 14.78s/it]2020-07-20 07:50:56,812 train loss in this epoch 0.696482\n",
      " 82%|████████▏ | 408/500 [4:40:37<18:28, 12.05s/it]2020-07-20 07:51:02,596 train loss in this epoch 0.696389\n",
      " 82%|████████▏ | 409/500 [4:40:43<15:25, 10.17s/it]2020-07-20 07:51:08,601 train loss in this epoch 0.696400\n",
      "2020-07-20 07:51:08,604 epoch 409, checkpoint!\n",
      "2020-07-20 07:56:26,797 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 07:56:27,356 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 07:57:14,000 using threshold -0.7295\n",
      "2020-07-20 07:57:14,242 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 82%|████████▏ | 410/500 [4:46:54<2:57:55, 118.61s/it]2020-07-20 07:57:19,917 train loss in this epoch 0.696373\n",
      " 82%|████████▏ | 411/500 [4:47:00<2:05:41, 84.73s/it] 2020-07-20 07:57:25,596 train loss in this epoch 0.696339\n",
      " 82%|████████▏ | 412/500 [4:47:06<1:29:29, 61.02s/it]2020-07-20 07:57:31,560 train loss in this epoch 0.696527\n",
      " 83%|████████▎ | 413/500 [4:47:12<1:04:31, 44.50s/it]2020-07-20 07:57:37,288 train loss in this epoch 0.696427\n",
      " 83%|████████▎ | 414/500 [4:47:18<47:06, 32.87s/it]  2020-07-20 07:57:43,186 train loss in this epoch 0.696399\n",
      " 83%|████████▎ | 415/500 [4:47:23<35:06, 24.78s/it]2020-07-20 07:57:49,102 train loss in this epoch 0.696371\n",
      " 83%|████████▎ | 416/500 [4:47:29<26:45, 19.12s/it]2020-07-20 07:57:54,750 train loss in this epoch 0.696390\n",
      " 83%|████████▎ | 417/500 [4:47:35<20:51, 15.08s/it]2020-07-20 07:58:00,640 train loss in this epoch 0.696383\n",
      " 84%|████████▎ | 418/500 [4:47:41<16:50, 12.32s/it]2020-07-20 07:58:06,558 train loss in this epoch 0.696438\n",
      " 84%|████████▍ | 419/500 [4:47:47<14:02, 10.40s/it]2020-07-20 07:58:12,667 train loss in this epoch 0.696418\n",
      "2020-07-20 07:58:12,670 epoch 419, checkpoint!\n",
      "2020-07-20 08:03:30,090 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 08:03:30,647 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 08:04:16,264 using threshold -0.7295\n",
      "2020-07-20 08:04:16,573 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 84%|████████▍ | 420/500 [4:53:57<2:37:42, 118.28s/it]2020-07-20 08:04:22,591 train loss in this epoch 0.696450\n",
      " 84%|████████▍ | 421/500 [4:54:03<1:51:23, 84.60s/it] 2020-07-20 08:04:28,402 train loss in this epoch 0.696361\n",
      " 84%|████████▍ | 422/500 [4:54:09<1:19:15, 60.97s/it]2020-07-20 08:04:34,174 train loss in this epoch 0.696346\n",
      " 85%|████████▍ | 423/500 [4:54:14<56:59, 44.41s/it]  2020-07-20 08:04:40,073 train loss in this epoch 0.696457\n",
      " 85%|████████▍ | 424/500 [4:54:20<41:37, 32.86s/it]2020-07-20 08:04:46,145 train loss in this epoch 0.696457\n",
      " 85%|████████▌ | 425/500 [4:54:26<31:01, 24.82s/it]2020-07-20 08:04:52,015 train loss in this epoch 0.696368\n",
      " 85%|████████▌ | 426/500 [4:54:32<23:36, 19.14s/it]2020-07-20 08:04:57,555 train loss in this epoch 0.696409\n",
      " 85%|████████▌ | 427/500 [4:54:38<18:19, 15.06s/it]2020-07-20 08:05:03,052 train loss in this epoch 0.696408\n",
      " 86%|████████▌ | 428/500 [4:54:43<14:37, 12.19s/it]2020-07-20 08:05:09,041 train loss in this epoch 0.696383\n",
      " 86%|████████▌ | 429/500 [4:54:49<12:13, 10.33s/it]2020-07-20 08:05:14,750 train loss in this epoch 0.696424\n",
      "2020-07-20 08:05:14,752 epoch 429, checkpoint!\n",
      "2020-07-20 08:10:27,844 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 08:10:28,402 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 08:11:14,361 using threshold -0.7295\n",
      "2020-07-20 08:11:14,921 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 86%|████████▌ | 430/500 [5:00:55<2:16:29, 116.99s/it]2020-07-20 08:11:20,642 train loss in this epoch 0.696435\n",
      " 86%|████████▌ | 431/500 [5:01:01<1:36:09, 83.61s/it] 2020-07-20 08:11:26,544 train loss in this epoch 0.696401\n",
      " 86%|████████▋ | 432/500 [5:01:07<1:08:20, 60.30s/it]2020-07-20 08:11:32,543 train loss in this epoch 0.696357\n",
      " 87%|████████▋ | 433/500 [5:01:13<49:08, 44.01s/it]  2020-07-20 08:11:38,571 train loss in this epoch 0.696413\n",
      " 87%|████████▋ | 434/500 [5:01:19<35:52, 32.61s/it]2020-07-20 08:11:44,352 train loss in this epoch 0.696486\n",
      " 87%|████████▋ | 435/500 [5:01:25<26:36, 24.56s/it]2020-07-20 08:11:50,068 train loss in this epoch 0.696401\n",
      " 87%|████████▋ | 436/500 [5:01:30<20:10, 18.91s/it]2020-07-20 08:11:55,760 train loss in this epoch 0.696400\n",
      " 87%|████████▋ | 437/500 [5:01:36<15:41, 14.94s/it]2020-07-20 08:12:01,475 train loss in this epoch 0.696425\n",
      " 88%|████████▊ | 438/500 [5:01:42<12:34, 12.18s/it]2020-07-20 08:12:07,048 train loss in this epoch 0.696422\n",
      " 88%|████████▊ | 439/500 [5:01:47<10:21, 10.19s/it]2020-07-20 08:12:13,026 train loss in this epoch 0.696445\n",
      "2020-07-20 08:12:13,028 epoch 439, checkpoint!\n",
      "2020-07-20 08:17:29,677 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 08:17:30,236 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 08:18:15,624 using threshold -0.7295\n",
      "2020-07-20 08:18:15,984 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 88%|████████▊ | 440/500 [5:07:56<1:57:49, 117.82s/it]2020-07-20 08:18:21,973 train loss in this epoch 0.696383\n",
      " 88%|████████▊ | 441/500 [5:08:02<1:22:51, 84.27s/it] 2020-07-20 08:18:27,586 train loss in this epoch 0.696389\n",
      " 88%|████████▊ | 442/500 [5:08:08<58:38, 60.67s/it]  2020-07-20 08:18:33,644 train loss in this epoch 0.696371\n",
      " 89%|████████▊ | 443/500 [5:08:14<42:04, 44.29s/it]2020-07-20 08:18:39,718 train loss in this epoch 0.696411\n",
      " 89%|████████▉ | 444/500 [5:08:20<30:38, 32.82s/it]2020-07-20 08:18:45,690 train loss in this epoch 0.696424\n",
      " 89%|████████▉ | 445/500 [5:08:26<22:42, 24.77s/it]2020-07-20 08:18:51,678 train loss in this epoch 0.696414\n",
      " 89%|████████▉ | 446/500 [5:08:32<17:13, 19.13s/it]2020-07-20 08:18:57,753 train loss in this epoch 0.696373\n",
      " 89%|████████▉ | 447/500 [5:08:38<13:26, 15.22s/it]2020-07-20 08:19:03,531 train loss in this epoch 0.696463\n",
      " 90%|████████▉ | 448/500 [5:08:44<10:44, 12.39s/it]2020-07-20 08:19:09,364 train loss in this epoch 0.696387\n",
      " 90%|████████▉ | 449/500 [5:08:50<08:51, 10.42s/it]2020-07-20 08:19:15,037 train loss in this epoch 0.696354\n",
      "2020-07-20 08:19:15,040 epoch 449, checkpoint!\n",
      "2020-07-20 08:24:34,928 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 08:24:35,486 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 08:25:19,953 using threshold -0.7295\n",
      "2020-07-20 08:25:20,200 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 90%|█████████ | 450/500 [5:15:00<1:38:47, 118.54s/it]2020-07-20 08:25:26,043 train loss in this epoch 0.696409\n",
      " 90%|█████████ | 451/500 [5:15:06<1:09:11, 84.73s/it] 2020-07-20 08:25:31,534 train loss in this epoch 0.696360\n",
      " 90%|█████████ | 452/500 [5:15:12<48:46, 60.96s/it]  2020-07-20 08:25:37,285 train loss in this epoch 0.696431\n",
      " 91%|█████████ | 453/500 [5:15:18<34:46, 44.40s/it]2020-07-20 08:25:43,112 train loss in this epoch 0.696407\n",
      " 91%|█████████ | 454/500 [5:15:23<25:10, 32.83s/it]2020-07-20 08:25:49,161 train loss in this epoch 0.696421\n",
      " 91%|█████████ | 455/500 [5:15:29<18:35, 24.79s/it]2020-07-20 08:25:55,003 train loss in this epoch 0.696383\n",
      " 91%|█████████ | 456/500 [5:15:35<14:00, 19.11s/it]2020-07-20 08:26:00,973 train loss in this epoch 0.696470\n",
      " 91%|█████████▏| 457/500 [5:15:41<10:52, 15.17s/it]2020-07-20 08:26:06,547 train loss in this epoch 0.696397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 458/500 [5:15:47<08:36, 12.29s/it]2020-07-20 08:26:12,220 train loss in this epoch 0.696386\n",
      " 92%|█████████▏| 459/500 [5:15:52<07:02, 10.30s/it]2020-07-20 08:26:18,157 train loss in this epoch 0.696440\n",
      "2020-07-20 08:26:18,160 epoch 459, checkpoint!\n",
      "2020-07-20 08:31:37,250 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 08:31:37,810 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 08:32:22,374 using threshold -0.7295\n",
      "2020-07-20 08:32:22,813 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 92%|█████████▏| 460/500 [5:22:03<1:18:55, 118.39s/it]2020-07-20 08:32:28,605 train loss in this epoch 0.696344\n",
      " 92%|█████████▏| 461/500 [5:22:09<54:59, 84.61s/it]   2020-07-20 08:32:34,379 train loss in this epoch 0.696369\n",
      " 92%|█████████▏| 462/500 [5:22:15<38:36, 60.96s/it]2020-07-20 08:32:40,159 train loss in this epoch 0.696409\n",
      " 93%|█████████▎| 463/500 [5:22:20<27:23, 44.41s/it]2020-07-20 08:32:46,096 train loss in this epoch 0.696382\n",
      " 93%|█████████▎| 464/500 [5:22:26<19:43, 32.87s/it]2020-07-20 08:32:51,822 train loss in this epoch 0.696352\n",
      " 93%|█████████▎| 465/500 [5:22:32<14:25, 24.72s/it]2020-07-20 08:32:57,999 train loss in this epoch 0.696416\n",
      " 93%|█████████▎| 466/500 [5:22:38<10:51, 19.16s/it]2020-07-20 08:33:04,018 train loss in this epoch 0.696395\n",
      " 93%|█████████▎| 467/500 [5:22:44<08:22, 15.22s/it]2020-07-20 08:33:09,765 train loss in this epoch 0.696392\n",
      " 94%|█████████▎| 468/500 [5:22:50<06:36, 12.38s/it]2020-07-20 08:33:15,628 train loss in this epoch 0.696473\n",
      " 94%|█████████▍| 469/500 [5:22:56<05:23, 10.42s/it]2020-07-20 08:33:21,628 train loss in this epoch 0.696403\n",
      "2020-07-20 08:33:21,629 epoch 469, checkpoint!\n",
      "2020-07-20 08:38:39,875 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 08:38:40,433 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 08:39:25,914 using threshold -0.7295\n",
      "2020-07-20 08:39:26,381 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 94%|█████████▍| 470/500 [5:29:07<59:15, 118.52s/it]2020-07-20 08:39:32,194 train loss in this epoch 0.696393\n",
      " 94%|█████████▍| 471/500 [5:29:12<40:56, 84.71s/it] 2020-07-20 08:39:37,947 train loss in this epoch 0.696362\n",
      " 94%|█████████▍| 472/500 [5:29:18<28:28, 61.02s/it]2020-07-20 08:39:43,683 train loss in this epoch 0.696400\n",
      " 95%|█████████▍| 473/500 [5:29:24<19:59, 44.44s/it]2020-07-20 08:39:49,491 train loss in this epoch 0.696422\n",
      " 95%|█████████▍| 474/500 [5:29:30<14:14, 32.85s/it]2020-07-20 08:39:55,549 train loss in this epoch 0.696439\n",
      " 95%|█████████▌| 475/500 [5:29:36<10:20, 24.81s/it]2020-07-20 08:40:01,628 train loss in this epoch 0.696416\n",
      " 95%|█████████▌| 476/500 [5:29:42<07:40, 19.19s/it]2020-07-20 08:40:07,513 train loss in this epoch 0.696360\n",
      " 95%|█████████▌| 477/500 [5:29:48<05:49, 15.20s/it]2020-07-20 08:40:13,190 train loss in this epoch 0.696387\n",
      " 96%|█████████▌| 478/500 [5:29:53<04:31, 12.34s/it]2020-07-20 08:40:19,287 train loss in this epoch 0.696440\n",
      " 96%|█████████▌| 479/500 [5:30:00<03:39, 10.47s/it]2020-07-20 08:40:25,221 train loss in this epoch 0.696380\n",
      "2020-07-20 08:40:25,223 epoch 479, checkpoint!\n",
      "2020-07-20 08:45:42,220 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 08:45:42,780 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 08:46:27,657 using threshold -0.7295\n",
      "2020-07-20 08:46:28,022 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 96%|█████████▌| 480/500 [5:36:08<39:18, 117.95s/it]2020-07-20 08:46:34,145 train loss in this epoch 0.696445\n",
      " 96%|█████████▌| 481/500 [5:36:14<26:43, 84.40s/it] 2020-07-20 08:46:39,955 train loss in this epoch 0.696355\n",
      " 96%|█████████▋| 482/500 [5:36:20<18:14, 60.82s/it]2020-07-20 08:46:45,925 train loss in this epoch 0.696377\n",
      " 97%|█████████▋| 483/500 [5:36:26<12:34, 44.37s/it]2020-07-20 08:46:51,572 train loss in this epoch 0.696415\n",
      " 97%|█████████▋| 484/500 [5:36:32<08:44, 32.75s/it]2020-07-20 08:46:57,133 train loss in this epoch 0.696384\n",
      " 97%|█████████▋| 485/500 [5:36:37<06:08, 24.59s/it]2020-07-20 08:47:03,117 train loss in this epoch 0.696428\n",
      " 97%|█████████▋| 486/500 [5:36:43<04:26, 19.01s/it]2020-07-20 08:47:08,994 train loss in this epoch 0.696424\n",
      " 97%|█████████▋| 487/500 [5:36:49<03:15, 15.07s/it]2020-07-20 08:47:14,919 train loss in this epoch 0.696469\n",
      " 98%|█████████▊| 488/500 [5:36:55<02:27, 12.33s/it]2020-07-20 08:47:20,465 train loss in this epoch 0.696415\n",
      " 98%|█████████▊| 489/500 [5:37:01<01:53, 10.29s/it]2020-07-20 08:47:26,215 train loss in this epoch 0.696464\n",
      "2020-07-20 08:47:26,216 epoch 489, checkpoint!\n",
      "2020-07-20 08:52:45,819 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 08:52:46,380 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 08:53:31,581 using threshold -0.7295\n",
      "2020-07-20 08:53:31,823 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      " 98%|█████████▊| 490/500 [5:43:12<19:46, 118.61s/it]2020-07-20 08:53:37,540 train loss in this epoch 0.696382\n",
      " 98%|█████████▊| 491/500 [5:43:18<12:42, 84.74s/it] 2020-07-20 08:53:43,666 train loss in this epoch 0.696472\n",
      " 98%|█████████▊| 492/500 [5:43:24<08:09, 61.16s/it]2020-07-20 08:53:49,444 train loss in this epoch 0.696465\n",
      " 99%|█████████▊| 493/500 [5:43:30<05:11, 44.54s/it]2020-07-20 08:53:54,914 train loss in this epoch 0.696423\n",
      " 99%|█████████▉| 494/500 [5:43:35<03:16, 32.82s/it]2020-07-20 08:54:00,415 train loss in this epoch 0.696362\n",
      " 99%|█████████▉| 495/500 [5:43:41<02:03, 24.63s/it]2020-07-20 08:54:05,930 train loss in this epoch 0.696403\n",
      " 99%|█████████▉| 496/500 [5:43:46<01:15, 18.89s/it]2020-07-20 08:54:11,535 train loss in this epoch 0.696380\n",
      " 99%|█████████▉| 497/500 [5:43:52<00:44, 14.91s/it]2020-07-20 08:54:17,587 train loss in this epoch 0.696419\n",
      "100%|█████████▉| 498/500 [5:43:58<00:24, 12.25s/it]2020-07-20 08:54:23,486 train loss in this epoch 0.696434\n",
      "100%|█████████▉| 499/500 [5:44:04<00:10, 10.34s/it]2020-07-20 08:54:29,190 train loss in this epoch 0.696378\n",
      "2020-07-20 08:54:29,192 epoch 499, checkpoint!\n",
      "2020-07-20 08:59:40,786 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 08:59:41,345 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 09:00:26,533 using threshold -0.7295\n",
      "2020-07-20 09:00:26,896 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n",
      "100%|██████████| 500/500 [5:50:07<00:00, 42.02s/it] \n",
      "2020-07-20 09:00:26,902 optimization Finished!\n",
      "2020-07-20 09:00:26,903 total time elapsed: 21007.6581s\n",
      "2020-07-20 09:00:26,904 retrieve best threshold...\n",
      "2020-07-20 09:05:44,906 valid_loss: 0.6964 AUC: 0.5045 Prec: 0.2541 Rec: 0.7152 F1: 0.3750\n",
      "2020-07-20 09:05:45,474 best threshold=-0.729537, f1=0.4000\n",
      "2020-07-20 09:05:45,486 testing...\n",
      "2020-07-20 09:06:30,072 using threshold -0.7295\n",
      "2020-07-20 09:06:30,406 test_loss: 0.6964 AUC: 0.5037 Prec: 0.2500 Rec: 0.9993 F1: 0.4000\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "t_total = time.time()\n",
    "logger.info(\"training...\")\n",
    "for epoch in tqdm(range(500)):\n",
    "    train(epoch, train_loader, valid_loader, test_loader)\n",
    "logger.info(\"optimization Finished!\")\n",
    "logger.info(\"total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "logger.info(\"retrieve best threshold...\")\n",
    "best_thr = evaluate(500, valid_loader, return_best_thr=True, log_desc='valid_')\n",
    "\n",
    "# Testing\n",
    "logger.info(\"testing...\")\n",
    "evaluate(500, test_loader, thr=best_thr, log_desc='test_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
