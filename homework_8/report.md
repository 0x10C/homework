# <center>  作业8 </center>
## 1.论文总结
&nbsp;&nbsp;&nbsp;&nbsp;首先，本文是基于hotpotQA数据集提出了大规模认知图谱结构的模型。不同于经典的SQuAD数据集，hotpotQA数据集给出的任务是要解决以多跳逻辑为主的阅读理解问题，这更加贴近实际阅读理解的问题，在现实的阅读理解问题中，往往答案是要根据多个观点支撑材料和多轮逻辑推导才能得出的。本文提出的双系统模型基础也借鉴了神经认知科学里的双加工系统理论，这不光从数学和实验结果可以保证本文提出的系统在多跳逻辑阅读理解任务中的可行性，并且也与其他学科的理论相结合，也为进一步的研究提供了不同角度的见解。

&nbsp;&nbsp;&nbsp;&nbsp;其次，对于新提出的hotpotQA数据集，对于数据的一些划分也十分合理，并且我认为从某种程度来说，在这样的数据划分下可以获得好的预测分数的模型，也十分适合用做下游任务处理，划分的方式包括：

&nbsp;&nbsp;A 根据包含的单跳逻辑问题和多跳逻辑问题的数量来区分train-easy，train-medium，train-hard，并且测试集和验证集的各类问题分布也在比较合理的范围。

&nbsp;&nbsp;B 根据定位Central question word(CWQ)来区分不同的问题类型，并且，这对的bad case分析也起到了很好的效果，可以更显著的分析黑箱模型的预测精度，更好的支持模型的可解释性。

&nbsp;&nbsp;C 最后回到CogQA本身，系统一以bert模型为主体，拼接所需要的段落向量，语义向量和提示向量，这里也充分用到了bert中的sep和cls记号，其中，使用cls记号来标识负采样样本也是十分的巧妙。系统二用到了GCN模型对建立的认知网络进行最优路径预测。
## 2.实验部署细节
&nbsp;&nbsp;&nbsp;&nbsp;本次实验的物理机配置为，32核128GB内存，1080TiGPU显存11GB。

数据预处理部分：安装了redis-0.6.0，90447条wiki数据共计耗时约90分钟。

模型部分：系统一的bert隐藏层神经元个数取768，激活函数使用gelu，学习效率，初始的前10%数据训练中设置为10<sup>-4</sup>,之后线性递减到0。权重衰减取0.01，优化器选择adam，&beta;<sub>1</sub>=0.9,dropout比率取0.2。系统二的GNN使用GCN模型，有两层隐藏层，隐藏层权重初始化使用均值为0，标准差为0.05的高斯分布，节点向量长度取768，激活函数使用gelu，学习效率设置为10<sup>-4</sup>，dropout比率取0.2，优化器选择adam，&beta;<sub>2</sub>=0.99，针对不同的问题类型（special question，alternative question，general question），也使用不同的预测策略。在实际实验中，受限于实验物理机器的性能，batch_size设置为2。

训练耗时:span extraction（TASK 1）大约耗时两个小时，answer prediction（TASK 2）大约耗时3个小时

预测评价耗时：大约18个小时，使用的数据集是全量wiki数据集，并且没有使用cuda加速。

## 3.结果对比分析

 数据集|结果来源|Ans_EM|Ans_F<sub>1</sub>|Ans_Prec|Ans_Recall|Sup_EM|Sup_F<sub>1</sub>|Sup_Prec|Sup_Recall|Joint_EM|Joint_F<sub>1</sub>|Joint_Prec|Joint_Recall
 -|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|-
 Dev|论文|37.6|49.4|52.2|49.9|23.1|58.5|64.3|59.7|12.2|35.3|40.3|36.5
 Dev|实验|29.2|36.7|48.4|39.6|19.6|51.7|55.0|56.9|10.3|27.5|38.1|29.1

实验结果和论文结果有所差距，主要是因为受限于物理机性能和训练时间，截断了训练数据以求得到结果。

## 4.模型改进
&nbsp;&nbsp;A 受限于物理机性能，针对训练时间长,针对系统一的bert模型，考虑了减少多头数量，从12调整至8；使用蒸馏bert或者albert

&nbsp;&nbsp;B 针对系统二的GNN模型，考虑了使用其他的图神经网络的变种GAT

从结果看，因为没有进行ablation 分析，考虑以上两个改进，训练时间没有太大差异，预测结果比实验结果大约提高3-5个百分点。
